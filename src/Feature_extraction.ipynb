{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37942e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63af59ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_paths=r\"C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1165f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "PoseLandmark = mp.solutions.pose.PoseLandmark\n",
    "mp_pose = mp.solutions.pose\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e74719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angle(a, b, c):\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cos_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee90066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_heel_strike(prev_y, current_y, threshold=0.005):\n",
    "    if prev_y is None:\n",
    "        return False\n",
    "    velocity = current_y - prev_y\n",
    "    return -threshold < velocity < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stride_length(prev_pos, curr_pos):\n",
    "    if prev_pos is None:\n",
    "        return 0.0\n",
    "    prev = np.array(prev_pos)\n",
    "    curr = np.array(curr_pos)\n",
    "    return float(np.linalg.norm(curr - prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23223ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_landmarks(landmark_list):\n",
    "    d = {}\n",
    "    for idx, lm_enum in enumerate(PoseLandmark):\n",
    "        name = lm_enum.name\n",
    "        lm = landmark_list[idx]\n",
    "        d[f\"{name}_x\"] = float(lm.x)\n",
    "        d[f\"{name}_y\"] = float(lm.y)\n",
    "        d[f\"{name}_z\"] = float(lm.z)\n",
    "        d[f\"{name}_visibility\"] = float(lm.visibility)\n",
    "\n",
    "    # Calculate joint angles (with error handling)\n",
    "    try:\n",
    "        d['left_knee_angle'] = compute_angle([d['LEFT_HIP_x'], d['LEFT_HIP_y']], [d['LEFT_KNEE_x'], d['LEFT_KNEE_y']], [d['LEFT_ANKLE_x'], d['LEFT_ANKLE_y']])\n",
    "        d['right_knee_angle'] = compute_angle([d['RIGHT_HIP_x'], d['RIGHT_HIP_y']], [d['RIGHT_KNEE_x'], d['RIGHT_KNEE_y']], [d['RIGHT_ANKLE_x'], d['RIGHT_ANKLE_y']])\n",
    "        d['left_hip_angle'] = compute_angle([d['LEFT_SHOULDER_x'], d['LEFT_SHOULDER_y']], [d['LEFT_HIP_x'], d['LEFT_HIP_y']], [d['LEFT_KNEE_x'], d['LEFT_KNEE_y']])\n",
    "        d['right_hip_angle'] = compute_angle([d['RIGHT_SHOULDER_x'], d['RIGHT_SHOULDER_y']], [d['RIGHT_HIP_x'], d['RIGHT_HIP_y']], [d['RIGHT_KNEE_x'], d['RIGHT_KNEE_y']])\n",
    "    except Exception:\n",
    "        # If landmarks missing, set angles to NaN\n",
    "        d['left_knee_angle'] = float('nan')\n",
    "        d['right_knee_angle'] = float('nan')\n",
    "        d['left_hip_angle'] = float('nan')\n",
    "        d['right_hip_angle'] = float('nan')\n",
    "    \n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb6b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_video_processing(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    return cap, fps, pose\n",
    "\n",
    "print('initialize_video_processing ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_for_gait(video_path, cycles_per_video=5):\n",
    "    cap, fps, pose = initialize_video_processing(video_path)\n",
    "    frame_number = 0\n",
    "    gait_count = 0\n",
    "    recording_cycle = False\n",
    "    current_cycle = []\n",
    "    prev_left_heel_y = None\n",
    "    prev_left_heel_pos = None\n",
    "    all_rows = []\n",
    "    \n",
    "    # Get total frames and duration for temporal context\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_duration = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    while cap.isOpened() and gait_count < cycles_per_video:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_number += 1\n",
    "        \n",
    "        # Calculate timestamp for this frame\n",
    "        timestamp = frame_number / fps\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(frame_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            lm = results.pose_landmarks.landmark\n",
    "            row = extract_frame_landmarks(lm)\n",
    "            \n",
    "            # Add temporal information\n",
    "            row['frame_idx'] = frame_number\n",
    "            row['timestamp'] = timestamp\n",
    "            row['fps'] = fps\n",
    "            row['video_duration'] = video_duration\n",
    "            row['total_frames'] = total_frames\n",
    "\n",
    "            left_heel_y = row.get('LEFT_HEEL_y')\n",
    "            left_heel_pos = [row.get('LEFT_HEEL_x'), row.get('LEFT_HEEL_y')]\n",
    "\n",
    "            if detect_heel_strike(prev_left_heel_y, left_heel_y):\n",
    "                if not recording_cycle:\n",
    "                    recording_cycle = True\n",
    "                    current_cycle = []\n",
    "                    cycle_start_frame = frame_number\n",
    "                    cycle_start_time = timestamp\n",
    "                    prev_left_heel_pos = left_heel_pos\n",
    "                else:\n",
    "                    recording_cycle = False\n",
    "                    gait_count += 1\n",
    "                    cycle_end_frame = frame_number\n",
    "                    cycle_end_time = timestamp\n",
    "                    stride_length = compute_stride_length(prev_left_heel_pos, left_heel_pos)\n",
    "                    step_time_sec = cycle_end_time - cycle_start_time\n",
    "                    cycle_frame_count = cycle_end_frame - cycle_start_frame\n",
    "                    \n",
    "                    # Add cycle-level temporal features to all frames in this cycle\n",
    "                    for r in current_cycle:\n",
    "                        r['stride_length'] = stride_length\n",
    "                        r['step_time_sec'] = step_time_sec\n",
    "                        r['cycle_frame_count'] = cycle_frame_count\n",
    "                        r['cycle_start_time'] = cycle_start_time\n",
    "                        r['cycle_end_time'] = cycle_end_time\n",
    "                    all_rows.extend(current_cycle)\n",
    "\n",
    "            prev_left_heel_y = left_heel_y\n",
    "\n",
    "            if recording_cycle:\n",
    "                current_cycle.append(row)\n",
    "\n",
    "    cap.release()\n",
    "    pose.close()\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a59d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gait_features_to_csv(video_paths, output_csv='gait_features.csv', cycles_per_video=5, allowed_exts=None):\n",
    "    allowed_exts = allowed_exts or ['.mp4', '.avi', '.mov', '.mkv']\n",
    "\n",
    "    if isinstance(video_paths, (str, Path)):\n",
    "        video_paths = [video_paths]\n",
    "\n",
    "    all_rows = []\n",
    "    video_items = []\n",
    "\n",
    "    # Flexible video discovery function: depth-first until videos are found\n",
    "    def find_videos_recursively(path, max_depth=10, current_depth=0):\n",
    "        \"\"\"Recursively find video files, returning videos found in the first directory that contains them.\n",
    "        This prefers videos closer to the provided path and only goes deeper when necessary.\"\"\"\n",
    "        videos_found = []\n",
    "        path = Path(path)\n",
    "\n",
    "        if not path.exists() or current_depth > max_depth:\n",
    "            return videos_found\n",
    "\n",
    "        if path.is_file() and path.suffix.lower() in allowed_exts:\n",
    "            return [path]\n",
    "\n",
    "        if path.is_dir():\n",
    "            # Check for videos directly in this folder\n",
    "            direct_videos = [child for child in sorted(path.iterdir()) if child.is_file() and child.suffix.lower() in allowed_exts]\n",
    "            if direct_videos:\n",
    "                return direct_videos\n",
    "\n",
    "            # Otherwise, check subdirectories (depth-first)\n",
    "            for subdir in sorted([c for c in path.iterdir() if c.is_dir()]):\n",
    "                vids = find_videos_recursively(subdir, max_depth, current_depth + 1)\n",
    "                if vids:\n",
    "                    # Return as soon as we find videos in a deeper folder\n",
    "                    return vids\n",
    "\n",
    "        return videos_found\n",
    "\n",
    "    # Discover videos for all provided roots\n",
    "    for p in video_paths:\n",
    "        video_items.extend(find_videos_recursively(p))\n",
    "\n",
    "    if not video_items:\n",
    "        print('No video files found in provided paths. Writing empty CSV.')\n",
    "        out_dir = Path('Datasets')\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        df = pd.DataFrame(all_rows)\n",
    "        out_path = out_dir / output_csv\n",
    "        df.to_csv(out_path, index=False)\n",
    "        print(f'Saved {len(df)} rows to {out_path}')\n",
    "        return df\n",
    "\n",
    "    # Group videos by the folder where they were found (deepest folder)\n",
    "    videos_by_folder = {}\n",
    "    for v in video_items:\n",
    "        parent = Path(v).parent\n",
    "        videos_by_folder.setdefault(parent, []).append(v)\n",
    "\n",
    "    for folder, vids in videos_by_folder.items():\n",
    "        folder_name = folder.name or ''\n",
    "        for video_path in vids:\n",
    "            try:\n",
    "                rows = process_video_for_gait(str(video_path), cycles_per_video=cycles_per_video)\n",
    "            except Exception as e:\n",
    "                print(f'Error processing {video_path}: {e}')\n",
    "                continue\n",
    "            for r in rows:\n",
    "                r['gait_pattern'] = folder_name\n",
    "            all_rows.extend(rows)\n",
    "\n",
    "    # Build DataFrame and save to Datasets/\n",
    "    out_dir = Path('Datasets')\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    out_path = out_dir / output_csv\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f'Saved {len(df)} rows to {out_path}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b642ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Early Level\\001_KOA_01_EL.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Early Level\\001_KOA_02_EL.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Early Level\\002_KOA_01_EL.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Moderate Disease\\006_KOA_01_MD.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Moderate Disease\\014_KOA_02_MD.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Severe\\001_KOA_01_SV.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Severe\\012_KOA_02_SV.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Normal\\030_NM_01.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Parkinson’s Disease\\Parkinson’s Disease  Severe stage\\001_PD_01_SV.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Parkinson’s Disease\\Parkinson’s Disease Mild stage\\001_PD_01_ML.MOV: name 'initialize_video_processing' is not defined\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Parkinson’s Disease\\Parkinson’s Disease Moderate stage\\001_PD_01_MD.MOV: name 'initialize_video_processing' is not defined\n",
      "Saved 0 rows to Datasets\\test_empty_restored.csv\n",
      "Rows: 0\n",
      "Datasets files: ['Final_Gait_Features_Named.csv', 'test_empty.csv', 'test_empty_restored.csv', 'test_enhanced_empty.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df= extract_gait_features_to_csv(video_paths, output_csv='test_empty_restored.csv')\n",
    "print('Rows:', len(df))\n",
    "print('Datasets files:', [p.name for p in Path('Datasets').glob('*')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2a22230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Enhanced Flexible Navigation ===\n",
      "\n",
      "--- Test 1: Enhanced function with aggregated features ---\n",
      "Processing video 1/11: 001_KOA_01_EL.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Early Level\\001_KOA_01_EL.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 2/11: 001_KOA_02_EL.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Early Level\\001_KOA_02_EL.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 3/11: 002_KOA_01_EL.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Early Level\\002_KOA_01_EL.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 4/11: 006_KOA_01_MD.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Moderate Disease\\006_KOA_01_MD.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 5/11: 014_KOA_02_MD.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Moderate Disease\\014_KOA_02_MD.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 6/11: 001_KOA_01_SV.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Severe\\001_KOA_01_SV.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 7/11: 012_KOA_02_SV.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Knee Osteoarthritis\\Knee Osteoarthritis Severe\\012_KOA_02_SV.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 8/11: 030_NM_01.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Normal\\030_NM_01.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 9/11: 001_PD_01_SV.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Parkinson’s Disease\\Parkinson’s Disease  Severe stage\\001_PD_01_SV.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 10/11: 001_PD_01_ML.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Parkinson’s Disease\\Parkinson’s Disease Mild stage\\001_PD_01_ML.MOV: name 'initialize_video_processing' is not defined\n",
      "Processing video 11/11: 001_PD_01_MD.MOV\n",
      "Error processing C:\\Users\\Josemiles\\Desktop\\Datasets\\After\\KOA-PD-NM\\Parkinson’s Disease\\Parkinson’s Disease Moderate stage\\001_PD_01_MD.MOV: name 'initialize_video_processing' is not defined\n",
      "Saved 0 rows to Datasets\\enhanced_flexible_navigation_test.csv\n",
      "Data type: Video-level aggregated\n",
      "Enhanced extraction result: 0 video summaries\n",
      "\n",
      "--- Available CSV files in Datasets ---\n",
      "  enhanced_flexible_navigation_test.csv: 0.0 KB\n",
      "  Final_Gait_Features_Named.csv: 5338.7 KB\n",
      "  test_empty.csv: 0.0 KB\n",
      "  test_empty_restored.csv: 0.0 KB\n",
      "  test_enhanced_empty.csv: 0.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Test the enhanced flexible navigation\n",
    "print(\"=== Testing Enhanced Flexible Navigation ===\")\n",
    "\n",
    "# Test 1: Use the enhanced function with flexible navigation\n",
    "print(\"\\n--- Test 1: Enhanced function with aggregated features ---\")\n",
    "df_enhanced = extract_enhanced_gait_features_to_csv(\n",
    "    video_paths=video_paths,\n",
    "    output_csv='enhanced_flexible_navigation_test.csv',\n",
    "    include_raw_frames=False,  # Aggregated features\n",
    "    cycles_per_video=3  # Fewer cycles for faster testing\n",
    ")\n",
    "\n",
    "print(f\"Enhanced extraction result: {len(df_enhanced)} video summaries\")\n",
    "if len(df_enhanced) > 0:\n",
    "    print(\"Columns:\", list(df_enhanced.columns))\n",
    "    if 'disorder_label' in df_enhanced.columns:\n",
    "        print(\"Disorder labels found:\", df_enhanced['disorder_label'].value_counts().to_dict())\n",
    "    if 'total_frames' in df_enhanced.columns:\n",
    "        print(\"Total frames per video:\", df_enhanced[['video_id', 'total_frames', 'extracted_frames']].head())\n",
    "\n",
    "print(\"\\n--- Available CSV files in Datasets ---\")\n",
    "datasets_dir = Path('Datasets')\n",
    "if datasets_dir.exists():\n",
    "    csv_files = list(datasets_dir.glob('*.csv'))\n",
    "    for csv_file in csv_files:\n",
    "        size_kb = csv_file.stat().st_size / 1024\n",
    "        print(f\"  {csv_file.name}: {size_kb:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b0d3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Navigation Results Summary ===\n",
      "Latest CSV: enhanced_flexible_navigation_test.csv\n",
      "Error reading CSV: No columns to parse from file\n"
     ]
    }
   ],
   "source": [
    "# Quick validation of navigation results\n",
    "print(\"=== Navigation Results Summary ===\")\n",
    "\n",
    "# Check if any videos were found and processed\n",
    "datasets_path = Path('Datasets')\n",
    "if datasets_path.exists():\n",
    "    csv_files = list(datasets_path.glob('*.csv'))\n",
    "    latest_csv = max(csv_files, key=lambda f: f.stat().st_mtime) if csv_files else None\n",
    "    \n",
    "    if latest_csv:\n",
    "        print(f\"Latest CSV: {latest_csv.name}\")\n",
    "        \n",
    "        # Read and show key info about the latest results\n",
    "        try:\n",
    "            df_check = pd.read_csv(latest_csv)\n",
    "            print(f\"Rows processed: {len(df_check)}\")\n",
    "            \n",
    "            if 'disorder_label' in df_check.columns:\n",
    "                disorder_counts = df_check['disorder_label'].value_counts()\n",
    "                print(f\"Gait patterns found: {disorder_counts.to_dict()}\")\n",
    "            \n",
    "            if 'total_frames' in df_check.columns and 'extracted_frames' in df_check.columns:\n",
    "                print(\"Frame extraction summary:\")\n",
    "                for _, row in df_check[['video_id', 'total_frames', 'extracted_frames', 'extraction_efficiency']].head(3).iterrows():\n",
    "                    print(f\"  {row['video_id']}: {row['extracted_frames']}/{row['total_frames']} frames ({row['extraction_efficiency']:.2%})\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV: {e}\")\n",
    "    else:\n",
    "        print(\"No CSV files found\")\n",
    "else:\n",
    "    print(\"Datasets directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d022b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temporal_features(df_video):\n",
    "    \"\"\"\n",
    "    Compute temporal gait features for a single video (all frames belong to same disorder).\n",
    "    This creates summary statistics that capture temporal dynamics while maintaining \n",
    "    video-level coherence for musculoskeletal disorder classification.\n",
    "    \"\"\"\n",
    "    if len(df_video) == 0:\n",
    "        return {}\n",
    "        \n",
    "    temporal_features = {}\n",
    "    \n",
    "    # Video-level temporal info\n",
    "    temporal_features['extracted_frames'] = len(df_video)  # Frames with detected gait cycles\n",
    "    temporal_features['video_duration'] = df_video['video_duration'].iloc[0] if 'video_duration' in df_video else 0\n",
    "    temporal_features['avg_fps'] = df_video['fps'].iloc[0] if 'fps' in df_video else 30\n",
    "    \n",
    "    # Get actual total frames from video metadata\n",
    "    if 'total_frames' in df_video and len(df_video) > 0:\n",
    "        temporal_features['total_frames'] = int(df_video['total_frames'].iloc[0])\n",
    "    else:\n",
    "        # Fallback: calculate from duration and fps\n",
    "        if temporal_features['video_duration'] > 0 and temporal_features['avg_fps'] > 0:\n",
    "            temporal_features['total_frames'] = int(temporal_features['video_duration'] * temporal_features['avg_fps'])\n",
    "        else:\n",
    "            temporal_features['total_frames'] = temporal_features['extracted_frames']\n",
    "    \n",
    "    # Calculate extraction efficiency\n",
    "    if temporal_features['total_frames'] > 0:\n",
    "        temporal_features['extraction_efficiency'] = temporal_features['extracted_frames'] / temporal_features['total_frames']\n",
    "    else:\n",
    "        temporal_features['extraction_efficiency'] = 0.0\n",
    "    \n",
    "    # Gait cycle statistics\n",
    "    if 'step_time_sec' in df_video:\n",
    "        step_times = df_video['step_time_sec'].dropna()\n",
    "        if len(step_times) > 0:\n",
    "            temporal_features['avg_step_time'] = step_times.mean()\n",
    "            temporal_features['std_step_time'] = step_times.std()\n",
    "            temporal_features['cadence_steps_per_min'] = 60.0 / step_times.mean() if step_times.mean() > 0 else 0\n",
    "    \n",
    "    # Joint angle temporal dynamics (capture movement patterns)\n",
    "    angle_cols = [col for col in df_video.columns if 'angle' in col]\n",
    "    for angle_col in angle_cols:\n",
    "        if angle_col in df_video:\n",
    "            angles = df_video[angle_col].dropna()\n",
    "            if len(angles) > 1:\n",
    "                temporal_features[f'{angle_col}_mean'] = angles.mean()\n",
    "                temporal_features[f'{angle_col}_std'] = angles.std()\n",
    "                temporal_features[f'{angle_col}_range'] = angles.max() - angles.min()\n",
    "                # Temporal derivative (rate of change)\n",
    "                angle_diff = angles.diff().dropna()\n",
    "                if len(angle_diff) > 0:\n",
    "                    temporal_features[f'{angle_col}_velocity_mean'] = angle_diff.mean()\n",
    "                    temporal_features[f'{angle_col}_velocity_std'] = angle_diff.std()\n",
    "    \n",
    "    # Stride characteristics\n",
    "    if 'stride_length' in df_video:\n",
    "        strides = df_video['stride_length'].dropna()\n",
    "        if len(strides) > 0:\n",
    "            temporal_features['avg_stride_length'] = strides.mean()\n",
    "            temporal_features['std_stride_length'] = strides.std()\n",
    "            temporal_features['stride_consistency'] = 1.0 - (strides.std() / strides.mean()) if strides.mean() > 0 else 0\n",
    "    \n",
    "    # Temporal symmetry (left vs right limb timing)\n",
    "    left_heel_y = df_video.get('LEFT_HEEL_y', pd.Series())\n",
    "    right_heel_y = df_video.get('RIGHT_HEEL_y', pd.Series())\n",
    "    if len(left_heel_y) > 1 and len(right_heel_y) > 1:\n",
    "        left_movement = left_heel_y.diff().dropna()\n",
    "        right_movement = right_heel_y.diff().dropna()\n",
    "        if len(left_movement) > 0 and len(right_movement) > 0:\n",
    "            # Cross-correlation for temporal symmetry\n",
    "            min_len = min(len(left_movement), len(right_movement))\n",
    "            left_move_norm = (left_movement[:min_len] - left_movement[:min_len].mean()) / left_movement[:min_len].std()\n",
    "            right_move_norm = (right_movement[:min_len] - right_movement[:min_len].mean()) / right_movement[:min_len].std()\n",
    "            temporal_features['limb_symmetry'] = np.corrcoef(left_move_norm, right_move_norm)[0, 1] if min_len > 1 else 0\n",
    "    \n",
    "    return temporal_features\n",
    "\n",
    "print('temporal feature computation ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb6820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhanced gait feature extraction ready\n"
     ]
    }
   ],
   "source": [
    "def extract_enhanced_gait_features_to_csv(video_paths, output_csv='enhanced_gait_features.csv', \n",
    "                                       cycles_per_video=5, allowed_exts=None, include_raw_frames=False):\n",
    "    \"\"\"\n",
    "    Enhanced gait feature extraction with temporal coherence for musculoskeletal disorder analysis.\n",
    "\n",
    "    Args:\n",
    "        video_paths: List of video file/folder paths\n",
    "        output_csv: Output CSV filename\n",
    "        cycles_per_video: Number of gait cycles to extract per video\n",
    "        allowed_exts: Video file extensions to process\n",
    "        include_raw_frames: If True, save frame-by-frame data; if False, save aggregated features per video\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with extracted features\n",
    "    \"\"\"\n",
    "    allowed_exts = allowed_exts or ['.mp4', '.avi', '.mov', '.mkv']\n",
    "\n",
    "    if isinstance(video_paths, (str, Path)):\n",
    "        video_paths = [video_paths]\n",
    "\n",
    "    all_rows = []\n",
    "    video_items = []\n",
    "\n",
    "    # Collect video files with flexible navigation\n",
    "    def find_videos_recursively(path, max_depth=10, current_depth=0):\n",
    "        \"\"\"Recursively find video files, returning videos found in the first directory that contains them.\"\"\"\n",
    "        videos_found = []\n",
    "        path = Path(path)\n",
    "\n",
    "        if not path.exists() or current_depth > max_depth:\n",
    "            return videos_found\n",
    "\n",
    "        if path.is_file() and path.suffix.lower() in allowed_exts:\n",
    "            return [path]\n",
    "\n",
    "        if path.is_dir():\n",
    "            direct_videos = [child for child in sorted(path.iterdir()) if child.is_file() and child.suffix.lower() in allowed_exts]\n",
    "            if direct_videos:\n",
    "                return direct_videos\n",
    "\n",
    "            for subdir in sorted([c for c in path.iterdir() if c.is_dir()]):\n",
    "                vids = find_videos_recursively(subdir, max_depth, current_depth + 1)\n",
    "                if vids:\n",
    "                    return vids\n",
    "\n",
    "        return videos_found\n",
    "\n",
    "    for p in video_paths:\n",
    "        video_items.extend(find_videos_recursively(p))\n",
    "\n",
    "    if not video_items:\n",
    "        print('No video files found in provided paths. Writing empty CSV.')\n",
    "        out_dir = Path('Datasets')\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        df = pd.DataFrame()\n",
    "        out_path = out_dir / output_csv\n",
    "        df.to_csv(out_path, index=False)\n",
    "        print(f'Saved empty CSV to {out_path}')\n",
    "        return df\n",
    "\n",
    "    # Group videos by the folder where they were found and process\n",
    "    videos_by_folder = {}\n",
    "    for v in video_items:\n",
    "        parent = Path(v).parent\n",
    "        videos_by_folder.setdefault(parent, []).append(v)\n",
    "\n",
    "    for video_idx, (folder, vids) in enumerate(videos_by_folder.items()):\n",
    "        folder_name = folder.name or 'unknown'\n",
    "        print(f'Processing folder {video_idx+1}/{len(videos_by_folder)}: {folder} (label: {folder_name})')\n",
    "        for video_path in vids:\n",
    "            print(f'  - {video_path.name}')\n",
    "            try:\n",
    "                frame_rows = process_video_for_gait(str(video_path), cycles_per_video=cycles_per_video)\n",
    "                if not frame_rows:\n",
    "                    print(f'    No gait cycles detected in {video_path.name}')\n",
    "                    continue\n",
    "\n",
    "                # Add video-level metadata to each frame\n",
    "                for row in frame_rows:\n",
    "                    row['video_id'] = video_path.stem\n",
    "                    row['video_path'] = str(video_path)\n",
    "                    row['disorder_label'] = folder_name\n",
    "                    row['gait_pattern'] = folder_name  # Backwards compatibility\n",
    "\n",
    "                if include_raw_frames:\n",
    "                    all_rows.extend(frame_rows)\n",
    "                else:\n",
    "                    df_video = pd.DataFrame(frame_rows)\n",
    "                    temporal_features = compute_temporal_features(df_video)\n",
    "\n",
    "                    video_summary = {\n",
    "                        'video_id': video_path.stem,\n",
    "                        'video_path': str(video_path),\n",
    "                        'disorder_label': folder_name,\n",
    "                        'gait_pattern': folder_name,\n",
    "                        'total_gait_cycles': len(df_video) // max(1, len(df_video['cycle_start_time'].dropna().unique())),\n",
    "                        **temporal_features\n",
    "                    }\n",
    "                    all_rows.append(video_summary)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error processing {video_path}: {e}')\n",
    "                continue\n",
    "\n",
    "    # Save results\n",
    "    out_dir = Path('Datasets')\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    out_path = out_dir / output_csv\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f'Saved {len(df)} rows to {out_path}')\n",
    "    print(f'Data type: {\"Frame-by-frame\" if include_raw_frames else \"Video-level aggregated\"}')\n",
    "    if 'disorder_label' in df.columns:\n",
    "        print(f'Disorder distribution: {df[\"disorder_label\"].value_counts().to_dict()}')\n",
    "\n",
    "    return df\n",
    "\n",
    "print('enhanced gait feature extraction ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a01b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Extract aggregated temporal features (one row per video)\n",
    "# This is ideal for traditional ML classifiers - each video becomes one sample with its disorder label\n",
    "print(\"=== Example 1: Video-level aggregated features ===\")\n",
    "# df_aggregated = extract_enhanced_gait_features_to_csv(\n",
    "#     video_paths=['path/to/video_folder/'],  # Folder with labeled videos\n",
    "#     output_csv='aggregated_gait_features.csv',\n",
    "#     include_raw_frames=False  # One row per video with temporal summary features\n",
    "# )\n",
    "\n",
    "print(\"=== Example 2: Frame-by-frame temporal sequences ===\")\n",
    "# This preserves full temporal information for sequence models (RNN/LSTM)\n",
    "# df_sequences = extract_enhanced_gait_features_to_csv(\n",
    "#     video_paths=['path/to/video_folder/'],\n",
    "#     output_csv='temporal_gait_sequences.csv', \n",
    "#     include_raw_frames=True  # Multiple rows per video, preserving time order\n",
    "# )\n",
    "\n",
    "print(\"=== Example 3: Test with existing empty folder ===\")\n",
    "# Test on empty list (should create empty CSV)\n",
    "df_test = extract_enhanced_gait_features_to_csv(\n",
    "    video_paths=[],\n",
    "    output_csv='test_enhanced_empty.csv',\n",
    "    include_raw_frames=False\n",
    ")\n",
    "print(f\"Test result: {len(df_test)} rows\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GaitEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
