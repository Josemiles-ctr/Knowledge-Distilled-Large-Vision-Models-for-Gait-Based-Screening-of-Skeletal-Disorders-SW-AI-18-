{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a187033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Basic shapes\n",
      "X shape: (2204, 64, 21)\n",
      "y shape: (2204,)\n",
      "\n",
      ">>> Missing / invalid values\n",
      "Total NaNs in X: 141056\n",
      "Total Infs in X: 0\n",
      "\n",
      ">>> Value range (ignoring NaNs):\n",
      "min: -7.0007123947143555 max: 68.93437957763672\n",
      "\n",
      ">>> Label distribution (counts):\n",
      "  KOA_Severe: 634\n",
      "  KOA_Mild: 506\n",
      "  KOA_Early: 336\n",
      "  PD_Early: 213\n",
      "  Normal: 208\n",
      "  PD_Mild: 170\n",
      "  PD_Severe: 57\n",
      "  NonAssistive: 55\n",
      "  Assistive: 25\n",
      "\n",
      ">>> Sample data (first sequence, first timestep, first 8 feature values):\n",
      "[0.32312822 0.47143033 0.38068298 0.10326837 0.5822616  0.30932415\n",
      "        nan 0.20501016]\n",
      "Corresponding label (y[0]): KOA_Early\n",
      "\n",
      ">>> meta file exists but couldn't be read (pandas error): cannot import name 'arrow_table_to_pandas' from 'pandas.io._util' (c:\\Users\\user\\Desktop\\GaitLab\\GaitEnv\\Lib\\site-packages\\pandas\\io\\_util.py)\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load sequence data and labels, perform strict sanity checks\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Adjust these paths if your files live elsewhere\n",
    "X_PATH = r\"C:\\Users\\user\\Desktop\\GaitLab\\GaitLab\\src\\keypoints_csv\\ts_data\\X_seq_len64_stride32.npy\"\n",
    "y_PATH = r\"C:\\Users\\user\\Desktop\\GaitLab\\GaitLab\\src\\keypoints_csv\\ts_data\\y_seq_len64_stride32.npy\"\n",
    "META_PATH = r\"C:\\Users\\user\\Desktop\\GaitLab\\GaitLab\\src\\keypoints_csv\\ts_data\\meta_seq_len64_stride32.csv\"  # optional\n",
    "\n",
    "# 1) Load\n",
    "X = np.load(X_PATH, allow_pickle=True)\n",
    "y = np.load(y_PATH, allow_pickle=True)\n",
    "\n",
    "# 2) Basic info\n",
    "print(\">>> Basic shapes\")\n",
    "print(\"X shape:\", X.shape)   # expected (N, timesteps, features)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "# 3) Numeric checks\n",
    "n_nans = int(np.isnan(X).sum())\n",
    "n_infs = int(np.isinf(X).sum())\n",
    "print(\"\\n>>> Missing / invalid values\")\n",
    "print(\"Total NaNs in X:\", n_nans)\n",
    "print(\"Total Infs in X:\", n_infs)\n",
    "\n",
    "# 4) Value range (ignore NaNs)\n",
    "if n_nans < X.size:\n",
    "    print(\"\\n>>> Value range (ignoring NaNs):\")\n",
    "    print(\"min:\", float(np.nanmin(X)), \"max:\", float(np.nanmax(X)))\n",
    "else:\n",
    "    print(\"\\n>>> All values are NaN in X â€” need to fix source extraction.\")\n",
    "\n",
    "# 5) Class distribution (text labels expected)\n",
    "try:\n",
    "    counts = Counter(y)\n",
    "    print(\"\\n>>> Label distribution (counts):\")\n",
    "    for k, v in counts.most_common():\n",
    "        print(f\"  {k}: {v}\")\n",
    "except Exception as e:\n",
    "    print(\"\\n>>> Could not compute label counts (labels may be numeric). Error:\", e)\n",
    "    print(\"Unique labels:\", np.unique(y))\n",
    "\n",
    "# 6) Show a tiny sample (first sequence first timestep and its label)\n",
    "print(\"\\n>>> Sample data (first sequence, first timestep, first 8 feature values):\")\n",
    "print(X[0, 0, :8])\n",
    "print(\"Corresponding label (y[0]):\", y[0])\n",
    "\n",
    "# 7) Optional: show meta file head if present\n",
    "if os.path.exists(META_PATH):\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        meta = pd.read_csv(META_PATH)\n",
    "        print(\"\\n>>> meta file sample:\")\n",
    "        display(meta.head(3))\n",
    "    except Exception as e:\n",
    "        print(\"\\n>>> meta file exists but couldn't be read (pandas error):\", e)\n",
    "\n",
    "# 8) Keep these variables in memory for next cells:\n",
    "# X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ae3bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10604\\3388182371.py:11: RuntimeWarning: All-NaN slice encountered\n",
      "  median_val = np.nanmedian(feat_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NaNs handled.\n",
      "Remaining NaNs: 0\n",
      "\n",
      "Encoded class names: ['Assistive' 'KOA_Early' 'KOA_Mild' 'KOA_Severe' 'NonAssistive' 'Normal'\n",
      " 'PD_Early' 'PD_Mild' 'PD_Severe']\n",
      "\n",
      "Data split completed:\n",
      "Train: (1763, 64, 21)  Val: (220, 64, 21)  Test: (221, 64, 21)\n",
      "\n",
      "âœ… Scaling complete.\n",
      "Feature value range after scaling (train): -6.8054714 to 64.63383\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Handle NaNs, encode labels, and split dataset\n",
    "# Note: pandas is already imported in previous cell, so we don't need to import it again\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Step 1: Handle NaNs ---\n",
    "# Replace NaNs with the median value per feature across all frames\n",
    "X_fixed = np.copy(X)\n",
    "for feat_idx in range(X_fixed.shape[2]):\n",
    "    feat_values = X_fixed[:, :, feat_idx].flatten()\n",
    "    median_val = np.nanmedian(feat_values)\n",
    "    if np.isnan(median_val):  # if all NaN in that column\n",
    "        median_val = 0.0\n",
    "    X_fixed[:, :, feat_idx] = np.nan_to_num(X_fixed[:, :, feat_idx], nan=median_val)\n",
    "\n",
    "print(\"âœ… NaNs handled.\")\n",
    "print(\"Remaining NaNs:\", np.isnan(X_fixed).sum())\n",
    "\n",
    "# --- Step 2: Encode labels ---\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "class_names = le.classes_\n",
    "print(\"\\nEncoded class names:\", class_names)\n",
    "\n",
    "# --- Step 3: Train/Val/Test split ---\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_fixed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"\\nData split completed:\")\n",
    "print(\"Train:\", X_train.shape, \" Val:\", X_val.shape, \" Test:\", X_test.shape)\n",
    "\n",
    "# --- Step 4: Feature scaling (per feature column) ---\n",
    "scaler = StandardScaler()\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[2])\n",
    "X_val_reshaped = X_val.reshape(-1, X_val.shape[2])\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[2])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped).reshape(X_train.shape)\n",
    "X_val_scaled = scaler.transform(X_val_reshaped).reshape(X_val.shape)\n",
    "X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "\n",
    "print(\"\\nâœ… Scaling complete.\")\n",
    "print(\"Feature value range after scaling (train):\", np.min(X_train_scaled), \"to\", np.max(X_train_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "717d719b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Teacher_LVM_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Teacher_LVM_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_6       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,568</span> â”‚ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_24          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_25          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_27          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,313</span> â”‚ dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_6       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m21\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚     \u001b[38;5;34m13,568\u001b[0m â”‚ input_layer_6[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_24          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚     \u001b[38;5;34m98,560\u001b[0m â”‚ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_25          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m263,168\u001b[0m â”‚ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_17 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_24 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_25 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_18 (\u001b[38;5;33mAdd\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_26 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_27          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_27 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         â”‚      \u001b[38;5;34m2,313\u001b[0m â”‚ dropout_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">577,545</span> (2.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m577,545\u001b[0m (2.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576,777</span> (2.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m576,777\u001b[0m (2.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to visualize model...\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "âš ï¸ Visualization file not found â€” likely missing Graphviz or pydot.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define and Visualize the Teacher Model (High-Capacity Temporal + Transformer Network)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "\n",
    "def build_teacher_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # --- Temporal Convolutional Layers ---\n",
    "    x = layers.Conv1D(128, kernel_size=5, padding='causal', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv1D(256, kernel_size=3, padding='causal', activation='relu', dilation_rate=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # --- Transformer Encoder Block ---\n",
    "    attn = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    x = layers.Add()([x, attn])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    ff = layers.Dense(256, activation='relu')(x)\n",
    "    ff = layers.Dense(256)(ff)\n",
    "    x = layers.Add()([x, ff])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    # --- Global Pooling ---\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # --- Classification Head ---\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"Teacher_LVM_Model\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Build & Compile ---\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "teacher = build_teacher_model(input_shape, num_classes)\n",
    "teacher.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --- Display Summary ---\n",
    "teacher.summary()\n",
    "\n",
    "# --- Visualize Model Architecture (optional) ---\n",
    "print(\"\\nAttempting to visualize model...\")\n",
    "try:\n",
    "    import os\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "    plot_path = \"teacher_model_architecture.png\"\n",
    "    plot_model(\n",
    "        teacher,\n",
    "        to_file=plot_path,\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        dpi=100\n",
    "    )\n",
    "\n",
    "    if os.path.exists(plot_path):\n",
    "        display(Image(filename=plot_path))\n",
    "        print(f\"âœ… Model visualization saved to: {plot_path}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Visualization file not found â€” likely missing Graphviz or pydot.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Skipping visualization due to error: {e}\")\n",
    "    print(\"ğŸ‘‰ To enable visualization, install Graphviz & pydot:\")\n",
    "    print(\"   pip install graphviz pydot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0762d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Class weights computed: {0: 9.794444444444444, 1: 0.728211482858323, 2: 0.48367626886145404, 3: 0.3863686171378479, 4: 4.452020202020202, 5: 1.180053547523427, 6: 1.1522875816993463, 7: 1.440359477124183, 8: 4.258454106280193}\n",
      "Epoch 1/50\n",
      "111/111 - 24s - 216ms/step - accuracy: 0.2547 - loss: 1.7104 - val_accuracy: 0.3364 - val_loss: 1.6205\n",
      "Epoch 2/50\n",
      "111/111 - 10s - 89ms/step - accuracy: 0.3590 - loss: 1.2789 - val_accuracy: 0.4000 - val_loss: 1.5207\n",
      "Epoch 3/50\n",
      "111/111 - 8s - 69ms/step - accuracy: 0.3988 - loss: 1.1350 - val_accuracy: 0.4591 - val_loss: 1.3668\n",
      "Epoch 4/50\n",
      "111/111 - 7s - 63ms/step - accuracy: 0.4509 - loss: 1.0440 - val_accuracy: 0.4864 - val_loss: 1.3145\n",
      "Epoch 5/50\n",
      "111/111 - 8s - 68ms/step - accuracy: 0.4600 - loss: 1.0103 - val_accuracy: 0.5136 - val_loss: 1.2534\n",
      "Epoch 6/50\n",
      "111/111 - 7s - 61ms/step - accuracy: 0.4714 - loss: 0.9448 - val_accuracy: 0.5227 - val_loss: 1.2368\n",
      "Epoch 7/50\n",
      "111/111 - 7s - 62ms/step - accuracy: 0.4923 - loss: 0.9155 - val_accuracy: 0.5091 - val_loss: 1.2464\n",
      "Epoch 8/50\n",
      "111/111 - 8s - 70ms/step - accuracy: 0.5167 - loss: 0.8568 - val_accuracy: 0.5636 - val_loss: 1.1139\n",
      "Epoch 9/50\n",
      "111/111 - 7s - 66ms/step - accuracy: 0.5394 - loss: 0.7944 - val_accuracy: 0.5409 - val_loss: 1.1086\n",
      "Epoch 10/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.5496 - loss: 0.8142 - val_accuracy: 0.5636 - val_loss: 1.0420\n",
      "Epoch 11/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.5666 - loss: 0.7404 - val_accuracy: 0.6182 - val_loss: 1.0030\n",
      "Epoch 12/50\n",
      "111/111 - 7s - 66ms/step - accuracy: 0.5944 - loss: 0.7164 - val_accuracy: 0.6045 - val_loss: 0.9484\n",
      "Epoch 13/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.5922 - loss: 0.7164 - val_accuracy: 0.6045 - val_loss: 1.0347\n",
      "Epoch 14/50\n",
      "111/111 - 8s - 68ms/step - accuracy: 0.6052 - loss: 0.6808 - val_accuracy: 0.6682 - val_loss: 0.8851\n",
      "Epoch 15/50\n",
      "111/111 - 7s - 61ms/step - accuracy: 0.6132 - loss: 0.6544 - val_accuracy: 0.6318 - val_loss: 0.9064\n",
      "Epoch 16/50\n",
      "111/111 - 7s - 63ms/step - accuracy: 0.6211 - loss: 0.6238 - val_accuracy: 0.6682 - val_loss: 0.8572\n",
      "Epoch 17/50\n",
      "111/111 - 7s - 63ms/step - accuracy: 0.6512 - loss: 0.6405 - val_accuracy: 0.6409 - val_loss: 0.9551\n",
      "Epoch 18/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.6449 - loss: 0.6383 - val_accuracy: 0.7273 - val_loss: 0.8041\n",
      "Epoch 19/50\n",
      "111/111 - 7s - 63ms/step - accuracy: 0.6665 - loss: 0.5884 - val_accuracy: 0.7273 - val_loss: 0.7398\n",
      "Epoch 20/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.6812 - loss: 0.5357 - val_accuracy: 0.7045 - val_loss: 0.7259\n",
      "Epoch 21/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.6863 - loss: 0.5547 - val_accuracy: 0.7409 - val_loss: 0.7325\n",
      "Epoch 22/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.6727 - loss: 0.6097 - val_accuracy: 0.6727 - val_loss: 0.8129\n",
      "Epoch 23/50\n",
      "111/111 - 7s - 65ms/step - accuracy: 0.7136 - loss: 0.5059 - val_accuracy: 0.7455 - val_loss: 0.7103\n",
      "Epoch 24/50\n",
      "111/111 - 7s - 62ms/step - accuracy: 0.7113 - loss: 0.4920 - val_accuracy: 0.7273 - val_loss: 0.7387\n",
      "Epoch 25/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.7226 - loss: 0.4804 - val_accuracy: 0.7409 - val_loss: 0.6948\n",
      "Epoch 26/50\n",
      "111/111 - 7s - 62ms/step - accuracy: 0.7391 - loss: 0.4594 - val_accuracy: 0.7545 - val_loss: 0.6206\n",
      "Epoch 27/50\n",
      "111/111 - 7s - 59ms/step - accuracy: 0.7164 - loss: 0.4973 - val_accuracy: 0.7182 - val_loss: 0.6778\n",
      "Epoch 28/50\n",
      "111/111 - 7s - 62ms/step - accuracy: 0.7345 - loss: 0.4624 - val_accuracy: 0.7409 - val_loss: 0.6200\n",
      "Epoch 29/50\n",
      "111/111 - 7s - 61ms/step - accuracy: 0.7442 - loss: 0.4396 - val_accuracy: 0.7318 - val_loss: 0.6983\n",
      "Epoch 30/50\n",
      "111/111 - 7s - 60ms/step - accuracy: 0.7538 - loss: 0.4176 - val_accuracy: 0.7636 - val_loss: 0.6827\n",
      "Epoch 31/50\n",
      "111/111 - 7s - 60ms/step - accuracy: 0.7396 - loss: 0.4535 - val_accuracy: 0.7273 - val_loss: 0.6815\n",
      "Epoch 32/50\n",
      "111/111 - 7s - 60ms/step - accuracy: 0.7674 - loss: 0.4177 - val_accuracy: 0.7545 - val_loss: 0.6942\n",
      "Epoch 33/50\n",
      "111/111 - 7s - 63ms/step - accuracy: 0.7646 - loss: 0.3893 - val_accuracy: 0.7636 - val_loss: 0.6017\n",
      "Epoch 34/50\n",
      "111/111 - 8s - 71ms/step - accuracy: 0.7646 - loss: 0.3976 - val_accuracy: 0.8136 - val_loss: 0.5221\n",
      "Epoch 35/50\n",
      "111/111 - 8s - 70ms/step - accuracy: 0.7890 - loss: 0.3682 - val_accuracy: 0.7773 - val_loss: 0.6595\n",
      "Epoch 36/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.8032 - loss: 0.3505 - val_accuracy: 0.8091 - val_loss: 0.5153\n",
      "Epoch 37/50\n",
      "111/111 - 7s - 61ms/step - accuracy: 0.7952 - loss: 0.3666 - val_accuracy: 0.7909 - val_loss: 0.5526\n",
      "Epoch 38/50\n",
      "111/111 - 7s - 63ms/step - accuracy: 0.7975 - loss: 0.3354 - val_accuracy: 0.8227 - val_loss: 0.5373\n",
      "Epoch 39/50\n",
      "111/111 - 7s - 63ms/step - accuracy: 0.8077 - loss: 0.3247 - val_accuracy: 0.8045 - val_loss: 0.5131\n",
      "Epoch 40/50\n",
      "111/111 - 8s - 70ms/step - accuracy: 0.8094 - loss: 0.3301 - val_accuracy: 0.8182 - val_loss: 0.5054\n",
      "Epoch 41/50\n",
      "111/111 - 7s - 61ms/step - accuracy: 0.8140 - loss: 0.3135 - val_accuracy: 0.8227 - val_loss: 0.5293\n",
      "Epoch 42/50\n",
      "111/111 - 7s - 64ms/step - accuracy: 0.8100 - loss: 0.3202 - val_accuracy: 0.8136 - val_loss: 0.5270\n",
      "Epoch 43/50\n",
      "111/111 - 7s - 66ms/step - accuracy: 0.8196 - loss: 0.3032 - val_accuracy: 0.8000 - val_loss: 0.5748\n",
      "Epoch 44/50\n",
      "111/111 - 7s - 65ms/step - accuracy: 0.8304 - loss: 0.2965 - val_accuracy: 0.8273 - val_loss: 0.5537\n",
      "Epoch 45/50\n",
      "111/111 - 7s - 65ms/step - accuracy: 0.8355 - loss: 0.2866 - val_accuracy: 0.8227 - val_loss: 0.5108\n",
      "Epoch 46/50\n",
      "111/111 - 7s - 66ms/step - accuracy: 0.8503 - loss: 0.2706 - val_accuracy: 0.8091 - val_loss: 0.5364\n",
      "Epoch 47/50\n",
      "111/111 - 8s - 68ms/step - accuracy: 0.8559 - loss: 0.2605 - val_accuracy: 0.8273 - val_loss: 0.4948\n",
      "Epoch 48/50\n",
      "111/111 - 7s - 66ms/step - accuracy: 0.8480 - loss: 0.2814 - val_accuracy: 0.8318 - val_loss: 0.5239\n",
      "Epoch 49/50\n",
      "111/111 - 7s - 61ms/step - accuracy: 0.8576 - loss: 0.2569 - val_accuracy: 0.8182 - val_loss: 0.5462\n",
      "Epoch 50/50\n",
      "111/111 - 7s - 62ms/step - accuracy: 0.8406 - loss: 0.2689 - val_accuracy: 0.8500 - val_loss: 0.4946\n",
      "\n",
      "Teacher Test Accuracy: 77.83%\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Assistive       1.00      1.00      1.00         2\n",
      "   KOA_Early       0.74      0.82      0.78        34\n",
      "    KOA_Mild       0.79      0.82      0.81        51\n",
      "  KOA_Severe       0.82      0.66      0.73        64\n",
      "NonAssistive       1.00      1.00      1.00         5\n",
      "      Normal       0.89      0.81      0.85        21\n",
      "    PD_Early       0.59      0.77      0.67        22\n",
      "     PD_Mild       0.74      0.82      0.78        17\n",
      "   PD_Severe       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.78       221\n",
      "   macro avg       0.84      0.86      0.85       221\n",
      "weighted avg       0.79      0.78      0.78       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Handle any remaining NaNs / Infs ---\n",
    "X_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_val   = np.nan_to_num(X_val, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "X_test  = np.nan_to_num(X_test, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# --- Compute class weights to handle imbalance ---\n",
    "unique_classes = np.unique(y_train)\n",
    "class_weights_values = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=unique_classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(zip(unique_classes, class_weights_values))\n",
    "print(\"âœ… Class weights computed:\", class_weights)\n",
    "\n",
    "# --- Callbacks ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_teacher_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# --- Train Teacher ---\n",
    "history_teacher = teacher.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,            # increase later if needed\n",
    "    batch_size=16,        # CPU-friendly\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- Evaluate on Test Set ---\n",
    "test_loss, test_acc = teacher.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTeacher Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# --- Detailed Classification Report ---\n",
    "y_pred = np.argmax(teacher.predict(X_test), axis=1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a865489c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Student\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Student\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d_7      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">585</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m21\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)         â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)         â”‚         \u001b[38;5;34m3,104\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚         \u001b[38;5;34m6,208\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling1d_7      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_28 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_29 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              â”‚           \u001b[38;5;34m585\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,105</span> (62.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,105\u001b[0m (62.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,105</span> (62.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,105\u001b[0m (62.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_student_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # --- Smaller Conv1D block ---\n",
    "    x = layers.Conv1D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "\n",
    "    # --- Another Conv1D block ---\n",
    "    x = layers.Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    \n",
    "    # --- Global Pooling and Dense ---\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    student_model = models.Model(inputs, outputs, name=\"Student\")\n",
    "    return student_model\n",
    "\n",
    "# --- Create student ---\n",
    "student = build_student_model(input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=len(class_names))\n",
    "student.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc5950b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
      "Epoch 1/50 - Loss: 0.4461 - Accuracy: 0.3352\n",
      "Epoch 2/50 - Loss: 0.4208 - Accuracy: 0.4634\n",
      "Epoch 3/50 - Loss: 0.4283 - Accuracy: 0.5383\n",
      "Epoch 4/50 - Loss: 0.4155 - Accuracy: 0.5837\n",
      "Epoch 5/50 - Loss: 0.4555 - Accuracy: 0.6137\n",
      "Epoch 6/50 - Loss: 0.2972 - Accuracy: 0.6410\n",
      "Epoch 7/50 - Loss: 0.3546 - Accuracy: 0.6506\n",
      "Epoch 8/50 - Loss: 0.2404 - Accuracy: 0.6761\n",
      "Epoch 9/50 - Loss: 0.1048 - Accuracy: 0.6948\n",
      "Epoch 10/50 - Loss: 0.1752 - Accuracy: 0.7056\n",
      "Epoch 11/50 - Loss: 0.1793 - Accuracy: 0.7334\n",
      "Epoch 12/50 - Loss: 0.3966 - Accuracy: 0.7544\n",
      "Epoch 13/50 - Loss: 0.2337 - Accuracy: 0.7425\n",
      "Epoch 14/50 - Loss: 0.0670 - Accuracy: 0.7669\n",
      "Epoch 15/50 - Loss: 0.5001 - Accuracy: 0.7799\n",
      "Epoch 16/50 - Loss: 0.0414 - Accuracy: 0.7799\n",
      "Epoch 17/50 - Loss: 0.2156 - Accuracy: 0.7918\n",
      "Epoch 18/50 - Loss: 0.1100 - Accuracy: 0.7981\n",
      "Epoch 19/50 - Loss: 0.1630 - Accuracy: 0.8247\n",
      "Epoch 20/50 - Loss: 0.0767 - Accuracy: 0.8361\n",
      "Epoch 21/50 - Loss: 0.6178 - Accuracy: 0.8383\n",
      "Epoch 22/50 - Loss: 0.0624 - Accuracy: 0.8264\n",
      "Epoch 23/50 - Loss: 0.3022 - Accuracy: 0.8440\n",
      "Epoch 24/50 - Loss: 0.0451 - Accuracy: 0.8627\n",
      "Epoch 25/50 - Loss: 0.0018 - Accuracy: 0.8718\n",
      "Epoch 26/50 - Loss: 0.0392 - Accuracy: 0.8752\n",
      "Epoch 27/50 - Loss: 0.1191 - Accuracy: 0.8712\n",
      "Epoch 28/50 - Loss: 0.0620 - Accuracy: 0.8769\n",
      "Epoch 29/50 - Loss: 0.0045 - Accuracy: 0.8622\n",
      "Epoch 30/50 - Loss: 0.0128 - Accuracy: 0.8712\n",
      "Epoch 31/50 - Loss: 0.1577 - Accuracy: 0.8922\n",
      "Epoch 32/50 - Loss: 0.1046 - Accuracy: 0.9013\n",
      "Epoch 33/50 - Loss: 0.0613 - Accuracy: 0.9115\n",
      "Epoch 34/50 - Loss: 0.0872 - Accuracy: 0.9126\n",
      "Epoch 35/50 - Loss: 0.0038 - Accuracy: 0.9178\n",
      "Epoch 36/50 - Loss: 0.0400 - Accuracy: 0.9246\n",
      "Epoch 37/50 - Loss: 0.0113 - Accuracy: 0.9382\n",
      "Epoch 38/50 - Loss: 0.1121 - Accuracy: 0.9325\n",
      "Epoch 39/50 - Loss: 0.0239 - Accuracy: 0.9387\n",
      "Epoch 40/50 - Loss: 0.1056 - Accuracy: 0.9212\n",
      "Epoch 41/50 - Loss: 0.0173 - Accuracy: 0.9126\n",
      "Epoch 42/50 - Loss: 0.0156 - Accuracy: 0.9512\n",
      "Epoch 43/50 - Loss: 0.0235 - Accuracy: 0.9524\n",
      "Epoch 44/50 - Loss: 0.1055 - Accuracy: 0.9433\n",
      "Epoch 45/50 - Loss: 0.0058 - Accuracy: 0.9569\n",
      "Epoch 46/50 - Loss: 0.0495 - Accuracy: 0.9631\n",
      "Epoch 47/50 - Loss: 0.0719 - Accuracy: 0.9444\n",
      "Epoch 48/50 - Loss: 0.0049 - Accuracy: 0.9484\n",
      "Epoch 49/50 - Loss: 0.0219 - Accuracy: 0.9438\n",
      "Epoch 50/50 - Loss: 0.0089 - Accuracy: 0.9263\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "Student Test Accuracy: 83.71%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "temperature = 5.0\n",
    "alpha = 0.7\n",
    "batch_size = 16\n",
    "\n",
    "# --- Compute teacher predictions once for the full training set ---\n",
    "teacher_preds = teacher.predict(X_train, batch_size=batch_size)\n",
    "teacher_preds_soft = tf.nn.softmax(teacher_preds / temperature)\n",
    "\n",
    "# --- Create dataset including teacher soft targets ---\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train, teacher_preds_soft))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)\n",
    "\n",
    "# --- Custom training step with distillation ---\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "kl_loss = tf.keras.losses.KLDivergence()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y_true, teacher_soft):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = student(x, training=True)\n",
    "        hard_loss = loss_object(y_true, logits)\n",
    "        soft_loss = kl_loss(teacher_soft, tf.nn.softmax(logits / temperature)) * (temperature ** 2)\n",
    "        loss = alpha * soft_loss + (1 - alpha) * hard_loss\n",
    "    grads = tape.gradient(loss, student.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, student.trainable_variables))\n",
    "    train_acc_metric.update_state(y_true, logits)\n",
    "    return loss\n",
    "\n",
    "# --- Training loop ---\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_acc_metric.reset_state()\n",
    "    for step, (x_batch, y_batch, t_batch) in enumerate(train_dataset):\n",
    "        loss = train_step(x_batch, y_batch, t_batch)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss:.4f} - Accuracy: {train_acc_metric.result().numpy():.4f}\")\n",
    "\n",
    "# --- Evaluate on test set ---\n",
    "test_preds = student.predict(X_test, batch_size=batch_size)\n",
    "test_acc = tf.keras.metrics.sparse_categorical_accuracy(y_test, test_preds)\n",
    "print(f\"Student Test Accuracy: {tf.reduce_mean(test_acc).numpy() * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35558ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/dklEQVR4nO3dCbxN5fv//8s8z/McEhKZhyglhVRIiZQMoVKi+igJpSISooEoKUWpFA0qCpWhMkWKiqKMZcos1u/xvr//tf/7HIcczll78Ho+Hts5Z+99tnX2vdd0reu67jSe53kGAAAAAAAABChtkP8ZAAAAAAAAIASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAiEOvvPKKpUmTxn777bdILwrOQo888oj7/P3111+RXpS4NnfuXPc+6ysAALGIoBQAAMkM9Pi3zJkz23nnnWd33XWXbd26NZBlOHr0qE2cONEuvfRSy5s3r2XKlMnOOecc69Spk3333XcWK/R3FC1a1L2PH3/8caQXJ2Zp7MM/kye66bOLlDdz5kxr2LChFSxY0LJmzWplypSxNm3a2KxZs0LP2bRpkwvSLV++3GLV4MGD7b333ov0YgAA4lD6SC8AAACxZtCgQVa6dGk7ePCgffXVV/bCCy/YRx99ZKtWrXInpqnlwIEDdt1117kT3ksuucQeeughF5hSNtRbb71lkyZNsg0bNljx4sUt2n3++ee2efNmF1R5/fXXrVmzZpFepJg0atQo27t3b+hnfQ6nTJliI0eOtPz584fuv+iiiyK0hPFr+PDh9r///c8Fpfr27evW/V9++cVmz55tU6dOtaZNm4aCUo8++qj7rFetWtViNSh1/fXXW8uWLSO9KACAOENQCgCAZFIApWbNmu772267zfLly2cjRoyw999/39q1a3dGr71///4TBrZ0AqyAlAIOvXr1SvDYwIED3f2xYvLkyVa9enW79dZbXXBt3759li1bNos2//77rx07dswyZsxo0ShxkGDLli0uKKX7FQSJdydbX1L7c/HYY4/ZFVdcYZ9++ulxj2/bti3wZQIAIBZRvgcAwBlq1KiR+7p+/foEQZcaNWpYlixZXDZT27ZtbePGjQl+TyV4F1xwgS1ZssRlPunkWgGapPzxxx82btw4dxKcOCAl6dKls/vvv/+kWVIKmjVv3tyVzansr2zZsu7EWqV04X7++Wdr3bq1FS5c2JUo6jW1/Lt37w4957PPPrMGDRpY7ty5LXv27Fa+fPkTLntSGV/Tp093r6lSJ/2sZUuKSvuUiZIjRw7LmTOn1apVy954440Ez1m8eLFdddVVlidPHhfYqlKlij3zzDMJ3mfdEuvYsWOCwI0yzlTqpgwYZSDp/dH7tHr1ajt8+LANGDDAjWmuXLnc/3PxxRfbF198cdzrKoil/79y5cru/StQoIDLmvHLK/X3XHjhhUn+vXofmzRp4r7/9ddf3S0lnMrn8csvv7QbbrjBSpYs6f7uEiVKWO/evd34JPbTTz+5sdPfptfUcvfr1++45+3atcu9z/qc6H1TmakCSaezfMlZXzSGGsvff//9uMeU1aQg486dO0/5856YemXt2bPH6tevn+TjKucT9XrSZ1b0tycup9TnT+9PYkl9ZrUNULBRnz29vsbm0KFDSf7/Wif0mdN7rvdJn7mvv/46yb5fyu462RjpOQoaKxPTX/6klhkAgNNBphQAAGfIDxwoY0qeeOIJ69+/vztpVybV9u3bbcyYMe5EetmyZe7kz/f333+7zCudBN98881WqFChEwZnlJ1xyy23nPZy6kRYAaR7773XfVUJnQItOrl+6qmn3HMUfFFQRCe7d999tztR//PPP+2DDz5wAQadtP7www929dVXu+CPShkVwNCJbeKT3hOZMWOGKznT36zX18m3Svhuuumm45a3c+fOVqlSJRdI0Pum90/ZYv5zFRzTshQpUsTuuece93o//vijW179fDrUs0ulmd26dXN/m4Ikeo8mTJjgMuG6du1q//zzj7300kvuvfrmm28SlGV16dLFLbvGVeOvcVPAZ9GiRS7DTmOo11C5p4Isvm+//dbWrl1rDz/8sPv58ssvd1/PtFn9qX4ep02b5oIRd9xxh/ss6+/S8xQM0WO+77//3gXkMmTI4N4jBVa0Dqi/kv6vcPo/Veo6ZMgQW7p0qXsPFVAZOnRospcvOeuLXqtPnz6urFUZhuF035VXXumCmKfyeU+K/gYF0PQ36/f0GUlKxYoV3Tqi9Uzvld630ymnVGBQnweV5/bs2dMFll977TW3Diem+/QeKcinDMq0adO6z7SC5/oc1q5dO1ljpP9H46Lf098gCtgCAJAiPAAAcEomTpzoadc5e/Zsb/v27d7GjRu9qVOnevny5fOyZMni/fHHH95vv/3mpUuXznviiScS/O7KlSu99OnTJ7i/YcOG7vXGjh37n/9379693XOXLVuWrGVdv3596L79+/cf97zu3bt7WbNm9Q4ePOh+1uvr96ZNm3bC1x45cqR7jt6D03H11Vd79evXD/384osvuvdm27Ztoft27drl5ciRw6tTp4534MCBBL9/7Ngx9/Xff//1Spcu7ZUqVcrbuXNnks/x32fdErv11lvd7/r0XunvypkzZ4Jl8f+vQ4cOJbhP/2ehQoW8zp07h+77/PPP3Wv07NnzuP/PXyb9bZkzZ/YeeOCBBI/rd7Jly+bt3bvX/axlC1++U/HUU08lGPfkfB6T+nwMGTLES5Mmjff777+H7rvkkkvc2ITfF/73ycCBA91yhL830qpVK7e++FJrfZF69ep5NWrUSHDfN998417j1VdfPeXP+4kMGDDA/a7GrFmzZm5ZlyxZctzzvv32W/c8rZOJaXz1OUws8Wd21KhR7jXeeuut0H379u3zzj33XHf/F198ERqDcuXKeU2aNEkwHhpbrStXXHFFssdI9DcmtZwAAJwpyvcAAEimxo0bu7IllTcpY0NZRypHK1asmL377ruufEvZByrx8W/KwChXrtxx5V7KxFG5zH9Rpo6ojO10KbPDp0wfLZcyN5Qdo3Is8TNDPvnkkyTLrMTPXFHJnf7W5FCmi147vPeWSqdUEqQMFp8yoLSMDz74oCupCqfnirJoVDKpcsbwbJrw55wOLY/GN3F5pN9XSn/zjh07XAaUMp+UXeJ755133P+tDJXE/GXSe9yiRQvX+8nzvNBshG+++WaoPMvPkDrTLKnkfB7DPx8q19LzlNGjZdR7Lcpimj9/vstgU5lfUn9fuNtvvz3Bz/q86TPgf55Ta32RG2+80ZX6hZdA6j3Wa+j9P9XP+4moeblKSatVq+Z+X+WLyk5SrzRl66UkNbBXNqCajftUludnLvk0w5/KEZVJqPfZfz81nsq00tglXmf/a4wAAEhNBKUAAEim5557zgVNdMKsfkPr1q0L9QHSCaFO4nVCrcBG+E0nqokbICuQFd5EW31s1Kzavyn4IeqnJArUnC6V3bVq1cqdiOv1tEwqgfL/X1EZj8r7VMKj2dv0d+nvDe+vo5N99dJRSY/KpxSYU0DpVAJUCgocOXLEncir5E83/Y116tRxJXw+P5AQXt6W2Kk853ToPUiKeuqoZFFBMpW36f378MMPE7w3WiaVVp2onMvXoUMHV4qlcirRjG1bt249o/LMpCTn86jlUa8gLbsCrXqOehGJ/zfqs56c9zxx4EolcxLez+lM1peTUX8sla7pMyf6f1SGqNI2f306lc/7ySi4qjHU36OG5woGKYB3zTXXuBLQlKLeWOeee+5xgT/18gqn91M0gUDi91N/o8oUE/9t/zVGAACkJnpKAQCQTOqt4s++l5gCMzpxVA8oZdckppP9cOHZKaI+SAp++BQUULPkChUquJ9Xrlx5WtPKqz+OXksn4+pxo54wCq4oy+eBBx5IEFB6+umnXXBCmVA60VYPG/WbUU8kNYHWMivjQkE5BWXU40kn/upZo+cn9Xf7/MDTiRpEK+hRpkwZS0kaDz8jKVziBu8nGhO/EbfeE2UyqUeReu7o79T7cjrNyBX8UEBPr6veSfqq7CBl4aWkU/086r1QE30FCPV50OdNGVvqr6S/O7kZcb4TfRb88TjT9eVkFBxU1o8CpmqIrs+vAm/h/axO5fN+KrRe6f3TTb22tA6r2bgf1DuRE2X0aTxOth6diD9O6hF3ou1E4vf0v8YIAIDURFAKAIAUpGCPTuaUgXHeeecl+/fVnNnPXgrPWlB2h04eFbw4nWwaBbZUkqNyKQVBfOEzBobTzHG6qen2ggULXBBp7Nix9vjjj7vHlYGiciDdRowYYYMHD3blSwpUnSiwov9Lr3XXXXcdd7Kuk2n9XSqH0v/pN1JWM3BliCQl/DknC+boPfQzfMIlNTPbibz99tsuWKb3LzyQkLhMT8ukUi4Fd06WLaWxVFaNGqIrSPLee++55uenE4hIic+jgp1qsq5girK4fMoIDOcHDPWeB7l8p0tZfXfeeaetWbPGBU5V8qYspuR+3pNDAWu9j5s3b/7PUlJ9NhUwTuqzGR6cLVWqlHvP9V6Fv57+rqTWCQXJUjLAeSblsAAAnAzlewAApKDrrrvOBRbUbyZxpoF+VmDoZM4//3x3Munf1KNG1L9KQQtlcmhmssQU1FHGh2ZKS4of7AhfJs089vzzzyd4nvrIqFdSOJ2sKwjlTz/vlxSG87MyTjRFfXiWlAJv6o0TflNPIQWq/OdodjT1z1LGSuIyKP9vUO8eBTNGjRp13Il9+N+pE3X1zFI/JN+KFStOebbAE71/yoRZuHDhcf2o9ByNf2KJPw8KwqlEqnv37m42wvBgpCgD63SysE7n85jU36fvn3nmmQS/ozIwBTVffvlll3V0sr8vJZfvdGk89Prq36XSPc3U6PfsOtXPe1LUfyrx2PuU9RVeWuf/f0kFn/TZVEaW1kWfZv7buHFjguddddVVtmnTJhccDV+GF198McHztL3Qaw4fPtx9phILXweSQ39DUssPAMCZIlMKAIAUpBNCZVf07dvXNalWuZeCK8oSUjN0NSa+//77T+u1FXRSkELlRcrY0Qm2Mi0UHNAJtwIv6u+UFDWs1nPVa0a/r8wHTfWeOBCg6eSVyaR+PMpc0Qm7nqcTe53gi8r/VL7XvHlzl8Ghvj8KbqnUqUGDBidcfgWcFLxSgC0p1157rd19992upFABp5EjR7q+VbVq1XJZRVp+BZN0Mq5MFAUOXnjhBZf5otdVA2w1g9b7oP5ZylgSNeVWNpdK5rp06eKWV1kwlSpVOuVmznqv9Z6rJ5f+bo2nXkNBxPCT/8suu8wFm0aPHu36+zRt2tQFDNV3SI/pvfWpr5Z6M2nsKlas6P7mcMpCkzNpdn6qn0eV6+m5+l4le8q0UdP2pPoK6W/TOGt59fsKDOq1VcqpRtupsXynS2WWet81/urHpsyp5H7ek6LPoNapunXrujHWZ1pBG2W8aaz1d2h8/b9Rjfj1edHfpgCPeqjpfdPnW4EmvYYCs1q/lQ3pZzz5FJB+9tlnXRabmrfrc67lVOZXOK0T6h2lzEp9vrVOqA+XxlRZjBrXmTNnJvt9VLBLfc/0PqosUsuuvwEAgDN2xvP3AQBwltCU7tp1aor3//LOO+94DRo0cFOp61ahQgWvR48e3po1a0LP0ZTvlSpVStYy/Pvvv96ECRO8iy++2MuVK5eXIUMGN618p06d3PT2iZd1/fr1ofu+/vprr27dul6WLFm8okWLen369PE++eSTBFPKr1u3zk0RX7ZsWS9z5sxe3rx5vcsuu8ybPXt26HXmzJnjtWjRwr1GxowZ3dd27dp5a9euPeFyL1myxP0//fv3P+FzfvvtN/ec3r17h+6bMWOGd9FFF7llzpkzp1e7dm1vypQpCX7vq6++clPd58iRw73XVapU8caMGZPgOZMnT/bKlCnjlrdq1aru79YU93rvfHqv9P8/9dRTxy3bsWPHvMGDB7vnZ8qUyatWrZr3wQcfHPca/hjpNTTm+v8KFCjgNWvWzL0HiQ0bNsz9n3rtxPS6iV/7v+j/TTzup/p5XL16tde4cWMve/bsXv78+b2uXbt6K1ascK+nz1O4VatWea1atfJy587tPifly5dPMLYDBw50v7d9+/YEv5fU5zI11xcZP368+z/1+Thw4ECCx07l856UI0eOuNdt2bJl6DORNWtW97nQGBw6dCjB899//33v/PPP99KnT3/c+/n00097xYoVc69Rv35977vvvnN/q27hfv/9d+/aa691/4/G55577vFmzZqVYP31aVtw3XXXefny5XOvq2Vs06aNW3dPZ4x++ukn75JLLnHroR7T5x4AgJSQRv+ceWgLAAAAyaXyuN69e7ssocSzoAEAAMQ7glIAAAARoEOwCy+80PLly+dKqwAAAM429JQCAAAI0L59+2zGjBkuEKVZ795///1ILxIAAEBEkCkFAAAQIJXqqVG0ml/feeed9sQTT0R6kQAAACKCoBQAAAAAAAAClzb4/xIAAAAAAABnO4JSAAAAAAAACByNzs3s2LFjtmnTJsuRI4elSZMm0osDAAAAAAAQs9Qp6p9//rGiRYta2rQnzociKGXmAlIlSpSI9GIAAAAAAADEjY0bN1rx4sVP+DhBKTOXIeW/WTlz5oz04gAAAAAAAMSsPXv2uOQfP95yIgSlNAXh/1eyp4AUQSkAAAAAAIAz918tkmh0DgAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcPSUAgAAAAAAUevo0aN25MiRSC8GwmTIkMHSpUtnZ4qgFAAAAAAAiDqe59mWLVts165dkV4UJCF37txWuHDh/2xmfjIEpQAAAAAAQNTxA1IFCxa0rFmznlHwAykbLNy/f79t27bN/VykSJHTfi2CUgAAAAAAIOpK9vyAVL58+SK9OEgkS5Ys7qsCUxqj0y3lo9E5AAAAAACIKn4PKWVIITr5Y3Mm/b4ISgEAAAAAgKhEyV58jw1BKQAAAAAAAASOoBQAAAAAAEAcOOecc2zUqFEWK2h0DgAAAAAAYsY1Y74K9P+beXeDFCtpGzhwoD3yyCMpsFTxgaAUAAAAAABACti8eXPo+zfffNMGDBhga9asCd2XPXt2izWHDx+2jBkzpsprU74HAAAAAACQAgoXLhy65cqVy2VOhd83depUq1ixomXOnNkqVKhgzz//fILff+CBB+y8885zM9uVKVPG+vfvf9zsdjNnzrRatWq518ifP7+1atUqweP79++3zp07W44cOaxkyZL24osvJnh848aN1qZNG8udO7flzZvXWrRoYb/99lvo8Y4dO1rLli3tiSeesKJFi1r58uUttRCUAgAAAAAASGWvv/66y5xSsOfHH3+0wYMHu6DTpEmTQs9RIOmVV16x1atX2zPPPGPjx4+3kSNHhh7/8MMPXRDqqquusmXLltmcOXOsdu3aCf6fp59+2mrWrOkev/POO+2OO+4IZWspwNWkSRP3/3z55Zf29ddfu+ytpk2buowon15Xv/PZZ5/ZBx98EJ9Bqfnz59s111zjIm+KHr733nsJHvc8zw1YkSJFLEuWLNa4cWP7+eefEzxnx44d1r59e8uZM6eL8nXp0sX27t0b8F8CAAAAAABw8n5SChhdd911Vrp0afe1d+/eNm7cuNBzHn74Ybvoootcw3LFS+6//3576623Qo8roNW2bVt79NFHXcbVhRdeaH379k3w/yhgpWDUueee6zKvlE31xRdfhEoKjx07ZhMmTLDKlSu715g4caJt2LDB5s6dG3qNbNmyuedUqlTJ3eIyKLVv3z73Bj733HNJPj5s2DAbPXq0jR071hYvXuzeFEX0Dh48GHqOAlI//PBDKHqnQFe3bt0C/CsAAAAAAABOHv/49ddfXSKNMpP82+OPP+7u9yloVL9+fVfqp8cVpFLAyLd8+XK7/PLLT/p/ValSJfS9Xz64bds29/OKFSvsl19+cZlS/jKohE9xlvDlUMAqtfpIRU2j82bNmrlbUpQlpWkMNQCqb5RXX33VChUq5DKqFBlUutusWbPs22+/dalpMmbMGBcVHD58uMvAAgAAAAAAiCS/okvleHXq1EnwWLp06dzXhQsXusQbZUEpIUc9qdSDStlVPlWR/ZcMGTIk+FmBKWVH+ctRo0YNV0qYWIECBULfKynorJ59b/369bZlyxZXsufTgGjwNFAKSumrSvb8gJTo+WnTpnWZVYmbffkOHTrkbr49e/ak8l8DAAAAAADOVkqwUeLMunXrXOApKQsWLLBSpUpZv379Qvf9/vvvx2VBqd9Tp06dTms5qlev7rKxChYs6NogRVrUBqUUkPIHLpx+9h/TV72R4dKnT+9Sz/znJGXIkCEu8hiPrhnzlUW7mRn//xUsanWfF+klAABEAPvRFMJ+FADOSim5H82fJY11rJzV0vy1z9JlSDj73MEjR0/7dTOnSfhap2T7T6f3n/2z2cw7Fvr9R++/3Xr2G2y50h20po0a2KFDR+y7Fats5649du8dHa1cwSyuVE/ZUZpdT03Np0+fflxfKpXvlS1b1iXr/Pvvv/bRRx+53lGnQgGxp556ylWkDRo0yIoXL+4CX++++6716dPH/Ryks3L2PTUB2717d+im6RABAAAAAABSy20332ATRjxmE6dMt8oNW1jDlh3slanTrXTJYu7xa5s2co3P77rrLqtatarLnNLsfOEuvfRSmzZtms2YMcM9p1GjRvbNN9+c8jJkzZrV9eIuWbKka7SuRufqc6WeUpHInIraTCk14pKtW7e62fd8+llvvP8cv1mXT1FCzcjn/35SMmXK5G4AAAAAACC2PN+++mn/brm0f1pQOrZt5W7hbmp9tbudyLBhw9wtXK9evRL8rGCSbkn57bffjrtPzdHDKV4yadKkEy7DK6+8Yna2Z0ppekS9UaqVDO/9pF5R9erVcz/r665du2zJkiWh53z++eeugVfixmEAAAAAAACIHhHNlFLXd01FGN7cXBE89YRSKpmigZoesVy5ci5IpbQ1NQZr2bKle77SzJo2bWpdu3a1sWPH2pEjR1yam+oqmXkPAAAAAAAgekU0KPXdd9/ZZZddFvr53nvvdV9vvfVWly6mJlv79u2zbt26uYyoBg0a2KxZsyxz5syh39E0hgpEqdGXZt1r3bq1jR49OiJ/DwAAAAAAAGIgKKUGXZ7nnfDxNGnSuG7wup2IsqreeOONVFpCAAAAAAAAnFU9pQAAAAAAABC/CEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAABAjLr00kutV69eFovSR3oBAAAAAAAATlWJt686g98+nPxfaTMp2b+y/a8dNmDoaPtw9nzbuv0vy5Mrl11YqbwNuO9Oq1+nuqUpWNGmvzLGWl7V2KJRx44dbdeuXfbee++l6v9DUAoAAAAAACAFte7c0w4fOWKTxgyxMqWK29btf9ucLxfZ3zt3RXrRogrlewAAAAAAAClk1+499uWiJTa0/312WYM6VqpEMatdvYr1vaebXdu0kZ1T43L3vFYd73YZU/7PHe/uay1btkzwWirLU3meb9++fdahQwfLnj27FSlSxJ5++unj/v9Dhw7Z/fffb8WKFbNs2bJZnTp1bO7cuaHHX3nlFcudO7d98sknVrFiRfdaTZs2tc2bN7vHH3nkEZs0aZK9//77liZNGncL//2URFAKAAAAAAAghWTPltXd3vt4jh06dHy54LefTHNfJ44ebJtXzg/9fCr+97//2bx581zA6NNPP3XBoqVLlyZ4zl133WULFy60qVOn2vfff2833HCDCzr9/PPPoefs37/fhg8fbq+99prNnz/fNmzY4AJZoq9t2rQJBap0u+iiiyw1UL4HAAAAAACQQtKnT2+vjB5iXe8bYGMnvWnVK59vDS+qZW1bXmVVKpW3AvnzuuflzpnDChcqcMqvu3fvXnvppZds8uTJdvnl/5ddpYym4sWLh56j4NLEiRPd16JFi4aCTLNmzXL3Dx482N135MgRGzt2rJUtWzYUyBo0aJD7XplTWbJkcRlXhQsXttREphQAAAAAAEAKan3Nlbbp+3k249XnrGmjBjb362+seuPW9srU6af9mr/++qsdPnzYleP58ubNa+XLlw/9vHLlSjt69Kidd955Lrjk35Rdpd/3Zc2aNRSQEpUCbtu2zYJGphQAAAAAAEAKy5w5k11xaX1363/fnXZb74dt4LAx1rFtqySfnzZtWvO8fxPcp4ym5FA2Vbp06WzJkiXuazgFp3wZMmRI8Jj6RnmeZ0EjUwoAAAAAACCVnX/eubZv/4FQUOjo0WMJHi+QL0+o2bhv+fLloe+V2aTfW7x4cei+nTt32tq1a0M/V6tWzWVKKevp3HPPTXBLTilexowZ3eukNjKlAAAAACCljGtoUa37vEgvARD3/t6x0264rbd1bnedVTm/vOXIns2+W7HKhj37krVo2sg955wSRW3Olwutfu1qlilTRsuTO5c1alDXnnruZXv11VetXr16rnfUqlWrXKDJz3Tq0qWLa3aeL18+K1iwoPXr189lWPlUtte+fXs3Q59m5tPvbt++3ebMmWNVqlSx5s2bn9LfcM4557jZ+dasWeP+r1y5ch2XXZUSyJQCAAAAAABIIdmzZbM61avYyHGT7JIWt9gFDa+1/k+Otq63XG/PDunvnvP0ow/YZ/MWWIlqjaza5de5+5o0amD9+/e3Pn36WK1ateyff/5xwaVwTz31lF188cV2zTXXWOPGja1BgwZWo0aNBM9RQ3P93n333ef6TbVs2dK+/fZbK1my5Cn/DV27dnW/W7NmTStQoIB9/fXXlhrSeJEoGowye/bscVG/3bt3W86cOS2WXTPmK4t2MzP2s6jHFSQAOCuxH00h7EdxNiNTCmexlNyP5s+SxjpWzmqFipW0dBkyptjrlkv7p0W1AhUsVhw8eNDWr19vpUuXtsyZM59WnIVMKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAICocswz8/SNdyzSi4ITOHbszMcm/Rm/AgAAAAAAQArafcizfw4dtWw7t1v2XHktTTqFL9Kc8eseTBvlQa6DBy3aeZ5nhw8ftu3bt1vatGktY8aMp/1aBKUAAAAAAEBUOeqZTfnxoDUqeczK7D9o6dKceUBKvDS7LKrtTpm/MwhZs2a1kiVLusDU6SIoBQAAAAAAos4/h81m/HLYsqTXLY2lRFzqhQzPW1S78TWLBenSpbP06dNbmjMcFIJSAAAAAAAgKqmv1P5/dXMdps5Y5qPbLKplzmxnExqdAwAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIFLH/x/CQAAAjOuoUW97vMivQQAAACIADKlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4NIH/18CAAAAcMY1tKjXfV6klwAAEKfIlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAKXPvj/EkByXDPmK4t2M+9uEOlFiBmMJwAAwP/huAgAmVIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwEX17HtHjx61Rx55xCZPnmxbtmyxokWLWseOHe3hhx+2NGnSuOd4nmcDBw608ePH265du6x+/fr2wgsvWLly5SK9+AAAAIiwaJ/da2bGSC8BAACRE9WZUkOHDnUBpmeffdZ+/PFH9/OwYcNszJgxoefo59GjR9vYsWNt8eLFli1bNmvSpIkdPHgwossOAAAAAACAGM2UWrBggbVo0cKaN2/ufj7nnHNsypQp9s0334SypEaNGuUyp/Q8efXVV61QoUL23nvvWdu2bSO6/AAAAAAAAIjBTKmLLrrI5syZY2vXrnU/r1ixwr766itr1qyZ+3n9+vWurK9x48ah38mVK5fVqVPHFi5ceMLXPXTokO3ZsyfBDQAAAAAAAMGJ6kypBx980AWMKlSoYOnSpXM9pp544glr3769e1wBKVFmVDj97D+WlCFDhtijjz6ayksPAAAAAACAmMyUeuutt+z111+3N954w5YuXWqTJk2y4cOHu69nom/fvrZ79+7QbePGjSm2zAAAAAAAAIjxTKn//e9/LlvK7w1VuXJl+/33312m06233mqFCxd292/dutWKFCkS+j39XLVq1RO+bqZMmdwNAAAAAAAAkRHVQan9+/db2rQJk7lUxnfs2DH3fenSpV1gSn2n/CCUyv00C98dd9wRkWUGzkrjGlpU6z4v0ksAAAAAAIiloNQ111zjekiVLFnSKlWqZMuWLbMRI0ZY586d3eNp0qSxXr162eOPP27lypVzQar+/ftb0aJFrWXLlpFefAAAAAAAAMRiUGrMmDEuyHTnnXfatm3bXLCpe/fuNmDAgNBz+vTpY/v27bNu3brZrl27rEGDBjZr1izLnDlzRJcdAAAAAAAAMRqUypEjh40aNcrdTkTZUoMGDXI3AAAAAAAAxIaoDkoBACIg2nuECX3CAAAAgJiXsIs4AAAAAAAAEACCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkejcwAAAAAx4ZoxX1m0m5kx0ksAALGDTCkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIFLH/x/CQBA/LhmzFcWzWZmjPQSAAAAAEkjUwoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQODoKQUAAAAAQFLGNbSo131epJcAOG1kSgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcOmT8+Rjx47ZvHnz7Msvv7Tff//d9u/fbwUKFLBq1apZ48aNrUSJEqm3pAAAAAAAADi7MqUOHDhgjz/+uAs6XXXVVfbxxx/brl27LF26dPbLL7/YwIEDrXTp0u6xRYsWpf5SAwAAAAAAIP4zpc477zyrV6+ejR8/3q644grLkCHDcc9R5tQbb7xhbdu2tX79+lnXrl1TY3kBAAAAAABwtgSlPv30U6tYseJJn1OqVCnr27ev3X///bZhw4aUWj4AAAAAAACcreV7/xWQCqcsqrJly57JMgEAAAAAACDOJavRebh///3Xxo0bZ3PnzrWjR49a/fr1rUePHpY5c+aUXUIAAAAAAACcnZlSSenZs6dNnz7dLrvsMmvYsKHrJ9WpU6eUXToz+/PPP+3mm2+2fPnyWZYsWaxy5cr23XffhR73PM8GDBhgRYoUcY9rFsCff/45xZcDAAAAAAAAEciUUgCqVatWCfpMrVmzxs3AJ02aNLG6deum4KKZ7dy502VgKfClGf8KFCjgAk558uQJPWfYsGE2evRomzRpkpsBsH///m5ZVq9eTdYWAAAAAABArAelXn75ZRf4ef75561o0aJWvXp1u/32261169Z25MgRNzNfrVq1UnThhg4daiVKlLCJEyeG7lPgKTxLatSoUfbwww9bixYt3H2vvvqqFSpUyN577z03EyAAAAAAAABiuHxv5syZ1q5dO7v00kttzJgx9uKLL1rOnDmtX79+LjtJwSOV8KWkGTNmWM2aNe2GG26wggULWrVq1Vzwy7d+/XrbsmWLK9nz5cqVy+rUqWMLFy5M0WUBAAAAAABAhHpK3XjjjfbNN9/YypUrXYmcej0tWbLEli9fbs8995wrr0tJ69atsxdeeMHKlStnn3zyid1xxx2ul5UytkQBKVFmVDj97D+WlEOHDtmePXsS3AAAAAAAABDFjc5z587tsqSeeuop69Chg/3vf/+zgwcPpsrCHTt2zJUJDh482GVJdevWzbp27Wpjx449o9cdMmSIy6jyb8ryAgAAAAAAQBQGpTZs2GBt2rRxs9+1b9/eZS8pSypr1qx24YUXukbkKU0z6p1//vkJ7qtYsaJbFilcuLD7unXr1gTP0c/+Y0np27ev7d69O3TbuHFjii87AAAAAAAAUiAopayotGnTugwp9Xfq3r27ZcyY0R599FHXVFzZRwpapSTNvKcZ/sKtXbvWSpUqFWp6ruDTnDlzQo+rFG/x4sVWr169E75upkyZXD+s8BsAAAAAAACicPa97777zlasWGFly5Z1/aTCZ8FT9tL8+fNdWV9K6t27t1100UWufE8BL/Wz0v/h/z9p0qSxXr162eOPP+4yt7RMarqu2QFbtmyZossCAAAAAACACASlatSoYQMGDLBbb73VZs+e7cr4ElPPp5RUq1Ytmz59uiu3GzRokAs6jRo1ypUP+vr06WP79u1z//euXbusQYMGNmvWLMucOXOKLgsAAAAAAAAiEJR69dVX7b777nPZS1WrVrVx48ZZEK6++mp3OxFlSylgpRsAAAAAAADiLCilPk5vv/126i4NAAAAAAAAzgqn1Ohc5XHJkdznAwAAAAAA4OxySkGpc88915588knbvHnzCZ/jeZ599tln1qxZMxs9enRKLiMAAAAAAADOxvK9uXPn2kMPPWSPPPKIXXjhhVazZk03w52aie/cudNWr15tCxcutPTp07um5N27d0/9JQcAAAAAAEB8B6XKly9v77zzjm3YsMGmTZtmX375pS1YsMAOHDhg+fPnt2rVqtn48eNdllS6dOlSf6kBAAAAAABwdjQ6l5IlS7oZ+HQDAAAAAAAAUrWnFAAAAAAAAJCSCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAABEf1DqnHPOsUGDBtmGDRtSZ4kAAAAAAAAQ95IdlOrVq5e9++67VqZMGbviiits6tSpdujQodRZOgAAAAAAAMSl0wpKLV++3L755hurWLGi3X333VakSBG76667bOnSpamzlAAAAAAAAIgrp91Tqnr16jZ69GjbtGmTDRw40CZMmGC1atWyqlWr2ssvv2ye56XskgIAAAAAACBupD/dXzxy5IhNnz7dJk6caJ999pnVrVvXunTpYn/88Yc99NBDNnv2bHvjjTdSdmkBAAAAAABwdgalVKKnQNSUKVMsbdq01qFDBxs5cqRVqFAh9JxWrVq5rCkAAAAAAAAgRYJSCjapwfkLL7xgLVu2tAwZMhz3nNKlS1vbtm2T+9IAAAAAAAA4SyQ7KLVu3TorVarUSZ+TLVs2l00FAAAAAAAApEij823bttnixYuPu1/3fffdd8l9OQAAAAAAAJyFkh2U6tGjh23cuPG4+//880/3GAAAAAAAAJDiQanVq1db9erVj7u/WrVq7jEAAAAAAAAgxYNSmTJlsq1btx53/+bNmy19+mS3qAIAAAAAAMBZKNlBqSuvvNL69u1ru3fvDt23a9cue+ihh9ysfAAAAAAAAMB/SXZq0/Dhw+2SSy5xM/CpZE+WL19uhQoVstdeey25LwcAAAAAAICzULKDUsWKFbPvv//eXn/9dVuxYoVlyZLFOnXqZO3atbMMGTKkzlICAAAAAAAgrpxWE6hs2bJZt27dUn5pAAAAAAAAcFY47c7kmmlvw4YNdvjw4QT3X3vttSmxXAAAAAAAAIhjyQ5KrVu3zlq1amUrV660NGnSmOd57n59L0ePHk35pQQAAAAAAMDZPfvePffcY6VLl7Zt27ZZ1qxZ7YcffrD58+dbzZo1be7cuamzlAAAAAAAADi7M6UWLlxon3/+ueXPn9/Spk3rbg0aNLAhQ4ZYz549bdmyZamzpAAAAAAAADh7M6VUnpcjRw73vQJTmzZtct+XKlXK1qxZk/JLCAAAAAAAgLiT7EypCy64wFasWOFK+OrUqWPDhg2zjBkz2osvvmhlypRJnaUEAAAAAADA2R2Uevjhh23fvn3u+0GDBtnVV19tF198seXLl8/efPPN1FhGAAAAAAAAnO1BqSZNmoS+P/fcc+2nn36yHTt2WJ48eUIz8AEAAAAAAAAp1lPqyJEjlj59elu1alWC+/PmzUtACgAAAAAAAKkTlMqQIYOVLFnSNTsHAAAAAAAAApt9r1+/fvbQQw+5kj0AAAAAAAAgkJ5Szz77rP3yyy9WtGhRK1WqlGXLli3B40uXLj2tBQEAAAAAAMDZI9lBqZYtW6bOkgAAAAAAAOCskeyg1MCBA1NnSQAAAAAAAHDWSHZPKQAAAAAAACDwTKm0adNamjRpTvg4M/MBAAAAAAAgxYNS06dPT/DzkSNHbNmyZTZp0iR79NFHk/tyAAAAAAAAOAslOyjVokWL4+67/vrrrVKlSvbmm29aly5dUmrZAAAAAAAAEKdSrKdU3bp1bc6cOSn1cgAAAAAAAIhjKRKUOnDggI0ePdqKFSuWEi8HAAAAAACAOJfs8r08efIkaHTueZ79888/ljVrVps8eXJKLx8AAAAAAADiULKDUiNHjkwQlNJsfAUKFLA6deq4gBUAAAAAAACQ4kGpjh07JvdXAAAAAAAAgDPrKTVx4kSbNm3acffrvkmTJiX35QAAAAAAAHAWSnZQasiQIZY/f/7j7i9YsKANHjw4pZYLAAAAAAAAcSzZQakNGzZY6dKlj7u/VKlS7jEAAAAAAAAgxYNSyoj6/vvvj7t/xYoVli9fvuS+HAAAAAAAAM5CyQ5KtWvXznr27GlffPGFHT161N0+//xzu+eee6xt27aps5QAAAAAAAA4u2ffe+yxx+y3336zyy+/3NKn/79fP3bsmHXo0IGeUgAAAAAAAEidoFTGjBntzTfftMcff9yWL19uWbJkscqVK7ueUgAAAAAAAECqBKV85cqVczcAAAAAAAAg1XtKtW7d2oYOHXrc/cOGDbMbbrgh2QsAAAAAAACAs0+yg1Lz58+3q6666rj7mzVr5h4DAAAAAAAAUjwotXfvXtdXKrEMGTLYnj17kvtyAAAAAAAAOAslOyilpuZqdJ7Y1KlT7fzzz0+p5QIAAAAAAEAcS3aj8/79+9t1111nv/76qzVq1MjdN2fOHJsyZYpNmzYtNZYRAAAAAAAAZ3tQ6pprrrH33nvPBg8ebG+//bZlyZLFqlSpYrNnz7aGDRumzlICAAAAAADg7A5KSfPmzd0tsVWrVtkFF1yQEssFAAAAAACAOJbsnlKJ/fPPP/biiy9a7dq17cILL0yZpQIAAAAAAEBcO+2g1Pz5861Dhw5WpEgRGz58uOsvtWjRopRdOgAAAAAAAMSlZJXvbdmyxV555RV76aWXbM+ePdamTRs7dOiQ6zHFzHsAAAAAAABI8UwpNTgvX768ff/99zZq1CjbtGmTjRkz5pT/IwAAAAAAACDZmVIff/yx9ezZ0+644w4rV67cqf4aAAAAAAAAcPqZUl999ZVral6jRg2rU6eOPfvss/bXX3+d6q8DAAAAAAAAyQ9K1a1b18aPH2+bN2+27t2729SpU61o0aJ27Ngx++yzz1zACgAAAAAAAEiV2feyZctmnTt3dplTK1eutPvuu8+efPJJK1iwoF177bXJfTkAAAAAAACchZIdlAqnxufDhg2zP/74w6ZMmZJySwUAAAAAAIC4dkZBKV+6dOmsZcuWNmPGjJR4OQAAAAAAAMS5FAlKAQAAAAAAAMlBUAoAAAAAAACBIygFAAAAAACAwMVUUEqz/KVJk8Z69eoVuu/gwYPWo0cPy5cvn2XPnt1at25tW7dujehyAgAAAAAAIE6CUt9++62NGzfOqlSpkuD+3r1728yZM23atGk2b94827Rpk1133XURW04AAAAAAADESVBq79691r59exs/frzlyZMndP/u3bvtpZdeshEjRlijRo2sRo0aNnHiRFuwYIEtWrQoossMAAAAAACAGA9KqTyvefPm1rhx4wT3L1myxI4cOZLg/goVKljJkiVt4cKFJ3y9Q4cO2Z49exLcAAAAAAAAEJz0FuWmTp1qS5cudeV7iW3ZssUyZsxouXPnTnB/oUKF3GMnMmTIEHv00UdTZXkBAAAAAAAQ45lSGzdutHvuucdef/11y5w5c4q9bt++fV3pn3/T/wMAAAAAAIDgRHVQSuV527Zts+rVq1v69OndTc3MR48e7b5XRtThw4dt165dCX5Ps+8VLlz4hK+bKVMmy5kzZ4IbAAAAAAAAghPV5XuXX365rVy5MsF9nTp1cn2jHnjgAStRooRlyJDB5syZY61bt3aPr1mzxjZs2GD16tWL0FIDAAAAAAAgpoNSOXLksAsuuCDBfdmyZbN8+fKF7u/SpYvde++9ljdvXpfxdPfdd7uAVN26dSO01AAAAAAAAIjpoNSpGDlypKVNm9ZlSmlWvSZNmtjzzz8f6cUCAAAAAABAPAWl5s6dm+BnNUB/7rnn3A0AAAAAAACxIaobnQMAAAAAACA+EZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABC6qg1JDhgyxWrVqWY4cOaxgwYLWsmVLW7NmTYLnHDx40Hr06GH58uWz7NmzW+vWrW3r1q0RW2YAAAAAAADEeFBq3rx5LuC0aNEi++yzz+zIkSN25ZVX2r59+0LP6d27t82cOdOmTZvmnr9p0ya77rrrIrrcAAAAAAAAOLn0FsVmzZqV4OdXXnnFZUwtWbLELrnkEtu9e7e99NJL9sYbb1ijRo3ccyZOnGgVK1Z0gay6detGaMkBAAAAAAAQs5lSiSkIJXnz5nVfFZxS9lTjxo1Dz6lQoYKVLFnSFi5ceMLXOXTokO3ZsyfBDQAAAAAAAMGJmaDUsWPHrFevXla/fn274IIL3H1btmyxjBkzWu7cuRM8t1ChQu6xk/WqypUrV+hWokSJVF9+AAAAAAAAxGBQSr2lVq1aZVOnTj3j1+rbt6/LuvJvGzduTJFlBAAAAAAAQBz0lPLddddd9sEHH9j8+fOtePHiofsLFy5shw8ftl27diXIltLse3rsRDJlyuRuAAAAAAAAiIyozpTyPM8FpKZPn26ff/65lS5dOsHjNWrUsAwZMticOXNC961Zs8Y2bNhg9erVi8ASAwAAAAAAIOYzpVSyp5n13n//fcuRI0eoT5T6QGXJksV97dKli917772u+XnOnDnt7rvvdgEpZt4DAAAAAACIXlEdlHrhhRfc10svvTTB/RMnTrSOHTu670eOHGlp06a11q1bu1n1mjRpYs8//3xElhcAAAAAAABxEJRS+d5/yZw5sz333HPuBgAAAAAAgNgQ1T2lAAAAAAAAEJ8ISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQAAAAAAgMARlAIAAAAAAEDgCEoBAAAAAAAgcASlAAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAAAIHEEpAAAAAAAABI6gFAAAAAAAAAJHUAoAAAAAAACBIygFAAAAAACAwBGUAgAAAAAAQOAISgEAAAAAACBwBKUAAAAAAAAQOIJSAAAAAAAACBxBKQAAAAAAAAQuboJSzz33nJ1zzjmWOXNmq1Onjn3zzTeRXiQAAAAAAADEc1DqzTfftHvvvdcGDhxoS5cutQsvvNCaNGli27Zti/SiAQAAAAAAIF6DUiNGjLCuXbtap06d7Pzzz7exY8da1qxZ7eWXX470ogEAAAAAACAeg1KHDx+2JUuWWOPGjUP3pU2b1v28cOHCiC4bAAAAAAAAkpbeYtxff/1lR48etUKFCiW4Xz//9NNPSf7OoUOH3M23e/du93XPnj0W644c2GfRbs/Rfy3qRdFngTFNAYxnfI2nMKanjPGMr/EUxjS+xpTxjK/xjIkxZTzjazyFMY2vMd0TPeN5Jvz4iud5J31eGu+/nhHlNm3aZMWKFbMFCxZYvXr1Qvf36dPH5s2bZ4sXLz7udx555BF79NFHA15SAAAAAACAs8fGjRutePHi8ZsplT9/fkuXLp1t3bo1wf36uXDhwkn+Tt++fV1jdN+xY8dsx44dli9fPkuTJk2qL/PZTNHSEiVKuA9mzpw5I704SAGMaXxhPOML4xl/GNP4wnjGH8Y0vjCe8YcxDY7yn/755x8rWrToSZ8X80GpjBkzWo0aNWzOnDnWsmXLUJBJP991111J/k6mTJncLVzu3LkDWV78H20A2AjEF8Y0vjCe8YXxjD+MaXxhPOMPYxpfGM/4w5gGI1euXP/5nJgPSomynm699VarWbOm1a5d20aNGmX79u1zs/EBAAAAAAAg+sRFUOrGG2+07du324ABA2zLli1WtWpVmzVr1nHNzwEAAAAAABAd4iIoJSrVO1G5HqKHyiYHDhx4XPkkYhdjGl8Yz/jCeMYfxjS+MJ7xhzGNL4xn/GFMo0/Mz74HAAAAAACA2JM20gsAAAAAAACAsw9BKQAAAAAAAASOoBQAAAAAAAACR1AKAAAAAAAAgSMoBQBIFceOHYv0IgBAXGL7CkS3I0eOuK/MKQb8N4JSiCnhG3Y28vF/kM0Yx6Z33nnHfU2bNi1jCAApaNSoUbZy5Uq3fSUwFZ841o19vXv3tldeecUOHjxoadKkYRyB/0BQCjHB35gfOHDAff3333/dRp4Dsviig2x544033FeNMWLLyy+/bH369LEhQ4a4nzkYi19sf4Fg7d27195991275JJL7McffyQwFaf8Y5/Dhw+zD41Ry5YtszFjxrj1VecujCNwcgSlEPW0EdfG/JNPPrFbbrnFrrjiCmvZsqX9+uuvoSAG4seff/5pd955pz377LORXhSchqZNm9q1115r77//vj3++OPuPg7G4o9OhP3t77p162zp0qXuhFknUf7jiF0nWl9ZjyMre/bsNmXKFGvYsKELTK1evZrAVJyaNGmSderUKXQRFrHBXxfnzp1r5cuXt2HDhrnscQJT8Yvtb8rgjB5RTxvxGTNmWKtWraxy5crWuXNn++eff6xmzZq2fv36SC8eUliePHlcUGPJkiXuZ3bgsdU/oWjRojZo0CBr0KCBCyQPHz7cPcbBWPzQOPoBqX79+rmLBE2aNLFmzZrZAw88YH/99RcXDOLgQtDnn39uDz/8sN1www2uDEX7W06OI69YsWL23HPPWd26dV1wisBU/NFYKtj/008/hfab7D9jz4gRIyxTpkwuY2r69Ol26NAhjoXi+ALdxIkTrX///nbzzTfb4sWLbc+ePZFevJjCUSOingJQ6qHwyCOPuNvFF19sGzdutDZt2ljp0qVDz+OALLZop5zUmGXNmtUFHidPnmyzZ8/mJCiGxjNDhgzu+48++shlzaxdu9aeeuopAlNxxl8ndQV4woQJ9vTTT9v27dutUKFCNnXqVJfFitgeX51A6eLAvn37XHaOxvmmm26yHTt2RHrxzmr+9lOBqRdeeIHAVJz2kNJY3n///fbHH3/Y0KFD3f0cC8UGP0DRq1cvl/WfPn16F2D83//+5zKm6DEVn+OtthUKSG3ZssWNrS7Mjh8/3o03Tg1BKUQ9HRT/9ttvdv3117sTHx2EqYRv3Lhx7nEFL/QcrszHDm20tVP2x2z+/Pn2888/hx6/9NJL7cYbb7Q333zTbdDZeUcvf2z8A2btlHv06GE1atRwQYvzzz/fXn/9dRs8eHDoeYxnbPLHTSe+ulgwZ84c1ztM2+NPP/3UZcYpS65OnTruirBuiD0bNmywgQMHumDyyJEj3UnxqlWr3EF23rx5I714Z6XE21kpXry4C0xpfSMwFbuOHj2aYFz973PkyGE9e/a0hQsX2rZt2yK4hEiu1157zZVfqoWBWhlom3rBBRfYgAEDXMCfwFR8+eCDD1xZ9YcffugCUWpyr/W6VKlSljlz5kgvXszgLB5R65dffnFfCxcuHDqxVcneNddcE+o3pB21mghqQ4DY8Nhjj7kSLz+bYvny5daoUSPXO+GOO+6wzZs3u4NqlWtqXHfv3s3OO0r9/fffbmy089X4qB+YDsCU2di1a1e79dZbXdN6BZJ1gKZUdmE8Y4/WSf9kSRcBsmXL5g6slbk6a9Ysa926tcuK07grGKWLBWr0itijgKPGUJlRKtnTfleZyRpf+eKLLyhLiEA5pS7ePPjgg3b33XfbW2+9FQpMvfjii6HAFM3PY4cyoTSm6dKlcz8rwN++fXsX7Pf3jzo2+uqrr1xgSthvRp+xY8e62TDD6Ti2QoUKrqeUAvlZsmRxF220vmod1nnL/v37yX6LUYm3r0qYqFWrll144YUuOKX1ViXWSqbQ/lSJFfhvBKUQlZTqqj4WOtnRyl+uXDl31VbBKV0Z9MuEdBVXJUL16tWL9CLjFKnWWv1ndACt7KiqVavat99+67JrdDCmoKMa2p933nmuHOiJJ55wv8fOO7ook0IZbSql1UG1xid37tyu0bV/VVcH0EWKFAllSY0ePdr69u3rvmc8Y7OHVLdu3dyJkw6otW3W+tyuXTu3Lb799tvdc7Zu3eouIlDGFxv8E93w0rwCBQq4fetll13mJi/Qfle+//57mzZtmttHI9hyyuuuu85lQyko3LZtW5eJqu2tLvIoMFW/fn2rVKmSrVmzhszxKKdx/O6771xGxaJFi9x9ZcqUcUFF7SMVZFT7Ah0fKYihgLDWT/ab0UUZwjpGVQBC/b98Wi937drlsmS0Lmp/KXquKgXUi/HLL7+M4JLjTPjbV12A1XqpbbKOez/77DN3HKTsYl1kF5VsPvnkky44hZNjr4WoXeF1FV7NrvW9SoKUbaFo9L333usOkNV3SF91Rb5EiRKRXmScIvUBU3prtWrV3EG0Tnz0vU5stVNXurpOkjSz0KZNm9xVeY27cJUweihQrKBhx44dXWDKb3ResmRJNxNbeCaFmtfXrl3bBa00Aw3jGFv8EyFlwv3www/uREp9hnRApmw5XSy47bbb3IG4xl0HYwpY6cQZsTG+X3/9tQswigIbOonSOquAlAIefjaHylK0fivYjGAoeKHsKAX3NemLvipTUcEKndxqdjYFptRMWRltBC6in7aZKnXW8ZD6DikwpZYFCxYscBdvdFFOx7q68KPHtD76+1my4KLHlVde6Xrdah3VhRkFG0XHRcqW8gMT6pUqfgaqMmgaN24c0WVH8oUfu+r8UwFkZUE1b97cja0uuCvw6I+7jneVFadttI6Z8B88IIKOHTsW+v7o0aMJ7ps4caKXK1cu79tvv3U///XXX97999/vNWjQwKtZs6bXtm1bb+XKlRFacpzJWM+ZM8dbvny517x5c69QoULe2rVrj3v+J5984j3yyCNe9uzZvSeffDLgpcWJvP3226Hvp0+f7l122WXepZde6v3222/uvi+++MJLnz6917t3b2/btm3uvkOHDnk33HCD98orr4Q+B+GfB0S/ESNGeFdccYXXrl0778CBA+6+/fv3ey+//LJbR7VN1mdB2+cLL7zQO3z4sHvOv//+G+Elx6n46aefvDRp0rj9rvzyyy/eBRdc4NWvX9+bPXu2N3PmTK9Xr15ejhw5vBUrVkR6cc8aOi6aPHmy169fP/fzhg0bvFKlSnk9evRw657G7IknnnDbWGF9i37+tlE+++wz7/rrr/eqVavmffnllwme9/XXX3tjxozxihcv7sZZz0N06Nq1q/f666+Hfh43bpxXvXp1r1u3bt6qVavcfW+88YbbXnbo0MGdq3z//fdes2bN3LGRj/U1Ns2dO9e75557vHfffdf9rO3v008/7VWpUsXr2LGjt2bNGm/WrFluvHXfkSNH3PM47j05glKI+I7ZX0l37dqV4PHff//drdCDBw8Obbj1XN0OHjyYYMeO6Ba+IX7ooYe8qlWruo22xrhJkyZe4cKFQ4Epf+PtH5APGzbMa9iwoff333+zQY+wF1980atXr16CdW/atGkuGKExWrduXShYlTlzZhesUuCxbt26XsWKFUPrsR+ARmxQ8Enb4QIFCrgD73AaU6279913n/fwww97zz//fGgdDl+XEb38cdLJkoLHugCkdVQnUnXq1PHKlCnjnXfeeW4918UEpL7wfd2ff/7pLs7pxEeB4c6dO7v1bsuWLV6xYsVcwELrHmLLY4895n344YfuAtx1113nAlMLFiw47nmbN2/2Ro0a5dWuXdtbtmxZRJYVXoL1ceDAgcedg4wdO9aNoQJTP//8s7vvgw8+8M455xyvSJEiLrioizecu8Q2ra+6YKPzlvnz54fu3717tzdy5EivRo0a7vhXx0rXXHMNF+iSgaAUIkIR5fbt24cOvHTlNUuWLG5Dr0wLX//+/d1Bl4JQwslsbFPQ4tprr3WZUj5d+U0cmArfeGsHoJMiHYAjsrZu3Roam2+++ea4wFR4xtSSJUvc+qurRjrZ9XfMrMPRL6kx0tjrxChdunRe3759Q/efKPDEAVj0Xwj6559/EjyuYHLevHldhkY4nWDpxFgH3Uhd/tjs3bs3wc/+ybBOerVPlJ07d7qMjVdffdX78ccfI7TEOJ3t6nvvvedlzJgxFGSaN29eKDC1cOHC0PP97egff/zhlShRwgU+EHn+fk/ZiuGZ/H5gSuulLrzKvn37XLBx0aJFofHkgk3s0nb47rvv9nLmzOl17949wWP++Gq91jGTv/1mvE8NQSkETivta6+9Ftpga6XVfU899ZTLqKhcubJ38803uwCGDpobNWrkrsIjtukKgoJLGmM/cBEemGratKkLQK5evTrBY88884yXJ08eglJRQuurUpd1dV5jk1TG1Pr165PcEbNjjq0TJx1YqbxE22KV7GnstZ3WwdiAAQMSjCtlmdFNmW4qN/HHRye+ymJUaVj4mN14442uBHPPnj0RXNqzm7IrlCXesmVLV/LsBwNVYpk2bVpX0qX9oUr6dLxEsDC2aJ0bP368G8dw2q8qMKUMCz8w5VcHyFVXXeUuCLCNjZzFixe7rH3Zvn2716ZNG5f9FD6WfmBKAYukWoxwwSZ2L9D5ZdL6DOi8VNtfZTz6kirT40LsqSMohYhSDb12wv5VQWXKKJ25UqVKbsesnXCrVq3cAZrfnwaxSVf6lMasYIZqrRNTYEo7d6W7+ht1nRiprxQlI5GlA2idIPkUdFIZpoKF4QdjCkwpiKybX8qH2BF+IPXggw965cqVc4FkHXjddNNNrs+QLhSov5TGXusmYkOnTp0SBPy1DVYZWKZMmbwWLVq4YKMoC0cZjzpBFg6og6VsCvVoU//MSy65xF3EufPOO11JpQwZMsTtQ7Vu5suXz1u6dGmkFxnJoGCiSrk0htqHJg5SKGNKvaN0gc7vTSTvv/++67H6ww8/RGS54bm+en5vL/98RIFiletpPQ2/SKfAlI5nFbRKfBEWsSF83/fcc8+5IKMuvCozVeesajmjPosqcVdfPx9B49NHUAqBSNzE3KdGgBUqVHAbeT8w5T9fK75Kf7QT0IGzUiERG050IuP3wFBfoqQOrjTGiX+X7JrI2rRpk2tcrvXQDxj6QUSV56mRZ3hg6p133nFBjLvuuitCS4wzpYNrTUDgByZ0UqwTIr+0eseOHS7zUZ+JCRMmRHhpcTKJ97kaU+1b/e2qSud1sK2ebzqJUsNejb2CWAh+jLT91HbVN3ToULe/1Imv1jtRKdDHH3/stsGIvbFW6buCGOpLoxLMxMc5n376qQtYhQerlA1HcCOypc9aL3UuootuupjuZ++r6qNLly7HBabUpkTbUQL7sa1Pnz5e0aJF3ddBgwa54x4Fo/xzFn2vbfQDDzwQ6UWNeWn0z3/N0AekhD/++MMOHjxo5557rk2bNs1+/PFHe/jhh90U088//7wVL17cfe9Pner76KOPrHz58la2bNmILTtOnaYrTps2rfv+559/dlMZa/wyZcrkpqrWtPI1a9a0ChUquHGvWLHiSV8DkaV1tkePHrZz505buXKlFS5c2L788kv32IYNG2zChAk2atQoGzJkiHuezJ071y6++OLQNPKIDTocOHr0qJuyWutonz597IMPPnA/Dx8+3Lp16+Y+D6Lpj2fNmmWtW7e29OnTR3rRkcRYansrR44csQwZMrjvb731Vvvss89s6NCh1qJFC8uZM6ft27fP9u7daw8++KD99ddf9uGHH1q2bNncFPS5cuUKvQ5Sb5y+/fZb27Rpky1evNhy5MjhphoXrY8jRoxw04pXr17dTT9foECBSC82TkHi4xh/rDU9/IoVK6xdu3aWP39+t7/MmDGjuz/xtlTjr9/heCjyli5dao0aNbJWrVq57WTmzJntueees4IFC9ratWtt2LBhtnr1are/vOuuuxKMOce0sWnevHnWqVMne+utt9wx0bJly6xGjRruXLV9+/buOdu3b3fHStrHjhs3jv3lmYh0VAxnx5Uh1eGee+65LvVRVxLUF0ENAkWPaRpqzSzSunVr1xTQvx+xe8VXV5VUYqBU9dKlS7usOD/bTaV8uv/yyy930+QiusdSmVC6UqRGyMqoUN8on2ZQVH+h3LlzJ2j4KfROiH7hV3H9MVevIZVWa0IClRL5zXV1tVjfK0sjHNmM0Sm8D5/K8vwG2erZqPVY+93Ezc5VMqRy3fDSIaSut99+28uWLZvLItaEL5qd1j8O8tfR4cOHuzHTVXn9TIlI7GxX1RdMWRTKOA1vRaDJQHRcXL9+/dDxLvvM6KMx8dc3zXKprEWdxyg7RrOV+se1yphSg3ONqVoZ+FhXY0firDa1k1FmnEydOtUdD2mGYT97UbOiirJYT1QRhFNHUAqBUXmeTlw1e5NS0sOFB6ZUgx1+QIbY8+ijj7qg04wZM9wGWtNYqzeNduThgSmlwVLmFRvUU+rxxx93ja8VoFLfGZ/KSO655x43zuGNWRE7VNKlUk1p166dG2OVZk6aNCn0HK27urCQuEEvoo/6XZQvX96dCKtxtra1Cir7NMYKcuiEmf1tZGfZU+mPjn+0fvlNkrW9DW82rxOe0aNHhyaRQGxQyY9mzVO5l9pUaMY9zbwXHpjSeqoLeAT3o4vGJnGJrPaTCiKqybkutKpkLzwwpbYU6vtGcDG2+euiLhho/dQkIWph4AekRPtTJVJs3LgxdB+lmmeGoBQCoSvsOvjS1cCsWbN6V199dWj2vfDAlA6Qy5Yt63Xo0CFiy4ozo8wn7bR1IuQ31NVsXZrRSUFJBab8K/jasbPzji46Obryyitd8OnXX39192mMFJDSwZffl0ZBC/8KkmhMmYEtNu3fv99tm9VcWRScuvjii10gWWOpbbfWVU04cdFFF7HOxgAFNKZMmeK2uZkzZ/beeuut0FgnDkz5jVsRLPUWOv/88916pUleROuWAsFqnqsG9MyCGHv87aMyDosXL+599913oawLBYd1DKwZqMOb2+tiLNvV6KHG8hqrAgUKuHEMn5yncePG7iKc6DEd27Zt2zZ0UcfHeMYmjan6K4q2v5oZXJ+F8Gbmmo1YPVY1AQzHuymHAlekKr9lmfoIqUfFjh07bP369bZw4ULr2bOnq8P2qaa+Q4cOri5bfRMQG0aPHh3qfyH58uWz22+/3a688kqbP3++62GiMVUfomrVqtmYMWPspZdecp8F9VNQ3yH1TUDkqYfMPffc43rOqFdUmzZtXN+vXbt22b333mvffPONTZw40Ro2bGiTJ0+2X3/91apUqeJ+t1ChQq6WPryXDaKfxitLliw2ePBgN77qA6ceGVqntW6q11+DBg3s6quvtm3btrn+J6yz0U99ic477zzbvXu362WyYMECd7/G2u8L9sYbb7j+GPfff7/NmDEjtL9G6vHfY/WnWbdunevZpX2jjo9E65Z60qg/399//23XXnut6/eF6Pf111+HxlB92rZu3WqPPvqoW8dmzpxpbdu2tbFjx1rXrl3dMdI777zjnl+nTh1788032a5GCfXgU8+vcuXKuWMZna/079/fjZ96v91yyy22Z88et1527tzZHeOq15COlcLXcXpqxib1TZVFixa5/ai2x7Vr17Y5c+a4Y2PtN1u2bOnOZSdNmhTqGYYUkIIBLiABP3qsFMdatWq5ko+///7b3acMjLx583pXXXWVm1JVNKuBsjEQO1588UV3BeHNN99McL8/ffUtt9zi3XHHHaFUWP1cqlQp78Ybb+TqQhRSFoWu0uvqoEoNtO5qhiBdGezZs6e7Oqhp5HUFULePPvrIlZlwRTB2nCi9XKUKKjPxe/1pTNUzQZmNKhtS1o0/zpSZRC9/u6oeF3/++afL0lDpgdZpbYvDr/T6VOL3yy+/RGR5z0bKIj7nnHPc9lMzrWkGYl2ZV0a5T+uY9q8qiQ4vD0F0UtllhgwZEvTI1PeaMe/nn392Y+zPzKZMYx036RaegYPooXI89chUFpRm0Fu3bp0rwWzVqpVXuHBhN3aTJ08ObXOVWcVxUOxJ6jxE5y9VqlRxs9L6tA/Vsa4yypUtrnMYf3vNuKccglJIVaqdV+nAqFGj3AFyOO2oNfV0jRo1XHBKDeT8pnGIjYMw9QcL748QThtqpb3ee++9oZNYlYtojCnzil4HDx50ZbTp06d3wQj1plGDZPUS0n0KKuq+xAEOdsyxRSdDOjkKp8kJNCnByaaaZ5yjl789VS8/lRZ88cUX7mcFFydMmOACU+E9/BT0UFAEwY2NypzVaN4PUGgbOnv2bO/CCy90/Wm0/fVpv6mxQ3QbN26cOxYK79kWTvtPHecqQOWXbaphvdY/AvzRHZgaPHiwCyj6k7ioF2q/fv3cZAQrVqw47nfYP8am8AsCogsG+fPnd9vmcFqHdUHH356z/qYsglJIMUuXLk1wQLV582aXIaUTW9FjikBrVorFixe7+3T1oUePHu5Amdl+YqvmOlOmTMcFpBR08nuXiGYp0YxCutKkHhnqn+HvtGkIGN076JdeeskdaA8cODB0v05g/YwKAoqxSeO2cuVK10tImVG6GqhAsQ6udMCtE2O/3wkHXNEtqUkF3n33XXeB55FHHnEXfnyaZU/rdL58+dxFIGU96mr/jz/+GIElPzt99dVXrn+U9oULFy4M3a/1TD38dKKrXm7hx1GI/otzulijhsjhNJ4+HfNqXdOMpmpUr4Bx+/btQ4+znY1e6qWoxuVqdq0ZFH07d+50XzmOjX0KPCoDTv1Ufdu2bfOaNGniJm0KX0eTmq0YKYegFM6YVkyVdijryc+gEF3h00HWCy+84CLLmkpVDbCV+qqd+MyZM93z/FIgxAZlUSiFVQfX4TQLhYJOv//+e4L7FXBUE0g1ryfdNfYCU1pX//e//yV4jJ1xbEnqwFnr8ccff+wOtpWOrtR03XfttdcmaGCP6D5hCqeyeGW6+TMEaT3VtlbT0OsgW7TfbdiwoTvgDp+eHqlPAX1lXShAET6Lk2ic5syZ4zJRNdEEop/WJY2ltqPhdIKrmwLBPjVE1nM1eYRKgxJnZiD6A1M6vlXmv4/j2NiU+PhV2VA6/tH4KpFCF9s18YdmV9QFnsQN7JF6CEohxfjBCGVIqTeNVupbb73VTW+sFVszyaivlNLXFdDo2LEjJ7cxSGOrUpAsWbKEsmgUkFLvIT89/WTjylXB2KEDZ/UY0jTWCiojtgNSunqvkhFl0/izn6rP39SpU73LL7/cO/fcc12wQidPia/8I/oyNHQQrVlr/TFWtrF6EykTTuM6YsQIF4BSdpTGN7w8ntn2IkP7SB0T6QKdglDhdJKrklp/1lNEL6136oOqbFOVPSe+OJfUsZDfQ4zefLEZmFIJX+XKlb2uXbtGenGQAsdDOr71Eyn0vTKL1TdM+1CVU+u4SBnlvXv3JogckDT6JyUapuPspdlCNMuEZh/44Ycf3CwF48ePt5tvvtnNzrVq1SrbuXOnm8kra9as7ndat25tlSpVskGDBkV68XEa/v33X3vttdesW7duVqRIEStQoIBNnz7dSpYsmWD2tREjRrjPgWbzEmZmi82ZaF5//XU3y4xmDtKYI/b06dPH3n77bbeu5smTx22Xp0yZYhdffHHoOZpJRjNIrVmzxj7//HNmD4pimh0qe/bsVrZsWTtw4ICbVU8zJ2qmr0aNGrlZorQvrlmzppshUzPs6TPQpUuXSC/6WcHf12ld0qymuXPndrM6aTZLjZOOgbTv1CyXl156aaQXF6dh+/btbjZabTdbtWplv/zyi/3444/uWKhMmTInPd7xj5sROzQb5siRI+23335zx78cy8YWnaNqJlp58skn3WzDummfqBmGr7jiCveYZlt8//333Xmszl01+55mm0YAgop+4eyhWQly5crlosyJrwTpasNDDz3kGsjRyyK2aWzVe0azKIbP6uRTxoVKNUlxjn26SqQZo7iyG5vUK0Hrot/HRhNPJDVrpp8JSRPP2KGmycWLF/dWr17tfl6wYIErMRk6dGiCyUUuvfRSV0qP1OevP8o2VE9FzbSnsjyVys6bN889pkxFZV2ov5caYSO2S7vKli3rKgLUHFvCMytUHq0ZLhG9TrU3lDJr/PWbflKxSeegmvRDVQCabVol1ZdccslxrUdU3q6MZP84iMqe1EdQCmfEX0k1C8Xnn38eur9Lly6u75ACU/7U0++8844r59PBmZqiI/ZpbHXCq75Dffv2Dd2v8kylvfoHZuy8o4MfIDyTQKF+l51zbPDXu/vuu8/dRDNE6eRJZXyivieJZ0YVxjg2aF+qact1Uuxf6PH3uf44attcpEgRysJSSfj+zT+B0WQuOXLkcCc1mkBAZXmadU+zEc+fP989R+UiKv9Syci+ffsitvxImcCUjnnCm2Hrs9C8eXMXjFS5H6KDtpPqA6ZemertdqqTLIUfN7F/jC3+eH3//feu1YgmHfAnn1B7Cs04fbJjYy7QBSN9ENlYiE9+avK7775r9957r0uBVPmWygkmTJjgHtd9+tq2bVtXQqD014EDB1rp0qUjvfhIAZkzZ3bleRrj22+/3aWjr169OlS2mSFDBlfqlz49m5pI03q6ZMkS6969u1tPff9VUhme8rx161YrVKhQIMuL07Ny5Uo7ePCg1apVKzRuGsN8+fLZzJkz7ZZbbrGnnnrKunbt6u5Xqclff/1ld9xxh1uffZQmRCd/fV23bp0rCatWrZo9++yz9uCDD1qTJk1s9uzZVq5cOTe2r7zyin344Ye2aNEi91UlRUh5Ws9+//13t13Vvk6lWVoPVTqp9UyPFytWzMqXL+/G5Z577rGPPvrIzj33XJs/f767z29tgNiTP39+u+2229z3flnXkCFDXImmSjU5FooeU6dOtWeeecb++ecf2717t+3du9cOHTpkzz//vCvTypgx4wm3u365pdZZncOUKFEi4KVHcu3bt8+yZcsWOp7Rtljfq1xP7Qw6derkPg+33nqr7d+/3z777DO76KKLXJuDcKy3AQko+IU4NWvWLC9r1qzuakP41Vlfp06dXCmfH4Xm6kJ80lUEZUypJEjNkv0MKa4uRAdNLlC0aFHvvPPOc1fmlb6sZtfhkrpCFL6+jhs3zk1OoAbKiE6vv/66V6NGDa9z584JsmKGDx/uZkdVhlR4CdeOHTvcTF/+hAWIbv76qNmBlH2hbe6ePXvcfd99953XtGlTl4msDBxRY/MePXp4P/30U0SXO94dPHjQq1u3rivT88dITebz5MkTmjrev19l0NoG++WWiL9m2JpdT5UC2t9yLBQ9dAyj7EVlCftZpcqUUQVHhgwZEsxaGi78Zz1Hx7lLliwJeOmRXMqG0yQEmlzAp3HTPvLZZ5/1cufO7b76lMGqiQpU+YPIICiF06KNtHqPaAX205V1cKxZfx577DE3K4nv+uuvdyfEu3fvjuASI7UpKKnZvZhZJvpo3Wzbtq2rn1cPGqWta0YuBZl033+VpOhgLlOmTK4EF9FJ/RF0wK2gkx+UCKcpj3WipAMvzQyloJX6vmmmGdbV2DFjxgw3jiNHjvQ2btyY4DGVJlxxxRWulM8PejBrUDDHQyoHUVlI1apV3c9avzQLm4JTfmDK7yVVpkwZV96H+PPXX395/fr1cyWZBKSihwJRKp31L8aFB5q2bdvmdevWzUuXLp3ryRcu/HkqxVWgedq0aQEuOU73eEgl62pb4PfSDE+WUGDxiSeeCN2n89mrr77azRJPu5HIISiFM9KuXTvv2muvdVcdtFHXtNM6MFMTuVatWoWet2nTpoguJ4LtO6SNOllx0UW9hHRA5Qcs1LBTO2ddIaxevbo3efLkUEZF+E5ZB2I5c+YkIBXFFGhU9sWUKVOOe8w/IVbPGmVFqSm2sleV2aEGvP6JExMSRD+Npcbs0UcfDWXo6CRYE074fYq0DtepU8c10dbYsh1OeUmdtOg+nfwog61WrVruPgUnNA7Dhg1z2arq36aLeMom9htiI76bYRMUjjxtExWE6Nq1a4JxDN82Kohfrlw575ZbbjlhQErHQZq8ANFNvYx14UYTuWibm5guGOhYSMdBumig/Wnjxo29SpUq0Qc3wghK4ZT5G+gffvghdJVPqawXX3yxlzZtWpcRpY2AGjo+88wzbrafvXv3JvhdRDcFHlTalXgWiv8av/ANuA6+EV00fhojZUbpBMmnK/nKdrztttvciawCVOFXAZV1ox03B2LRTdluanYdXkKt1PVevXq5mWU6dOgQKuf74osvXPmXTqD99ZYr+bFB5ZYKJr700kve+vXr3bb6sssucwfgytDRrIqybNkyb8OGDZFe3LjkrzObN28+7gq8Tmh0bFS6dGk3m5OofEQX6pSlobHTBTsmeol+NMOOH7ogo8CDsr2VQXOisVE2uYL+iR/T+GuWaY6DopvGTftIlbHrHDScLt5o5lO1nPEv8PTs2dNdkFXG+F133RU6DuJ4KHLo3IVkNzW/77777M4773QNzbt16+aaq27atMk1jvOp2XWePHlcc0ehaW70UxPru+++27Jnz+6adaohshq1tmrVKjR+auDqN3sM/2z4DZVffPFFW7hwoT399NOWN2/eiPwdSJrGSOvstGnTrFevXla3bl23jr700kuWK1cuW7ZsmX3zzTfWsmVL9/xXX33V+vTpYxMnTnQNWxG9tF5u27bNNdTVOqtGykuXLnWNda+99lq3Pm/YsMG++OILu/TSSxP8rpos08Qzuve7aqJdsGBBt74WKVLEBg0a5Mb4yiuvdJOITJkyxTp37mxr1qxxv1e1atVIL3pcb0c3btzoGszv2LHDGjZsaPXq1bPGjRu7da927dr25ptvukledEz01VdfueMlNTbX+FWvXt1KlSoV6T8DJ0Ez7PigdU/HNFpn69Sp4yb4UEN6bVM7dux43PMPHDhgFSpUCB3vajy///5769Gjh1unOQ6Kbho3nXPqfDR84ogxY8a4Y5/33nvPcubM6SaY0HmK1vFdu3a5CUN8TEYQYREMiCHG6KqRrsiqMZzfXDVxlHrt2rXevffe6xrIqb8FYgd9h+KDeiKoAXL37t29wYMHu2bH4dQIW6nsynBUY9YTjevQoUO9mTNnBrTUOBNaX+vXr+/KD1Sep0ae48ePd1PRy6JFi9yY6ytig3+1/v3333clYeHbYJUn6Kq9MnP8zAyVnehqr34mQyN1qSebMtM0LurJpkbJyoTSfRoHZYy/9dZbrreXenwxHrGDZtjxQfs/ZSVqndR4at+oLKmnn37ajc2rr76a4BhW67SyTjXuiakPHGKDjmk15jfddJPbDquXpsrylDWuLHFlt6rVgbKkhMzG6EJQCv9JK6rSX9UEzm9qrjpdBaA0q5NfMqCTXwUwNPPI8uXLI7zUOB30HYptEyZM8IoVK+ZKZ1WaV7BgQS9jxowudd0v5xkyZIibFcj/+WQH14gd6imkYKSCieE9TfwLClp/VfKF2KGAlC4Eqe/FL7/8kuRzNBumyvh0IYgZ3YKjfaT6ZqoxroK9KnlXTzcFh2vXru1mJVY/KZ0A68RI2LZGN5phx09ASsc9CkqogbWCESqnVYm71lttL7Ve+rOC61i2efPmLigVHqSgr1Bs0qQTuiBQsWJF199Px0b+rNFqKaNxVgN0RB+CUkgg8UY4/Oc2bdp4Xbp0cTPs3Xnnna6puXon6Mq8piAXbfz//PPPwJcbZ46+Q7FNV+Z1IqRx8DMZ1QdDGW/q+danTx9337p167zs2bMnmAoXseu/TnTVDFuTUWg2KA6yY4d6Y2h7688QpF6NmsFW67kyMNT3Ys6cOV7Dhg1d42z6FAVPF2jUj0TZUMpW9KlfiTIxdPJbrVo1xiYG0Aw7PugcROPoTwbhj48u1mg2NmXSaJ+oXm8KMGo9VT9cZT0y6Ufs89db9ZBS37/EtA9VgNJPpkB0ISiF4yhlWQdTSmcN3+EOGDDANerUhvyGG25wVwV18jtw4ECXRYXY5o/1Y4895q4uaAet7Apd+VXmhejgWgdefiNAlZQoNZqDsMiOmzIX1dzRDyb646PH9L1mgVJgSpkXonVWzXcVoEJ8rse6IqgrhM2aNXNjzawysUUH1GpSr6b0+l77XwWglAGgkjFlrWqslR3pN7FH8JQxrsCUbnPnzj3ucZrmxgaaYcfP+qjWBMpgVGNrn4JSuojuT8Sj/aO2qQpgKajv7x9ZX+OLv57quEf70auuusqd3xB4jE5p9E+k+1ohehw5csTq169v3333nWsG16JFC9e888Ybb3SPr1271jXMVVNPNchVA0E1O1ezuMmTJ7smczQ1j35q8qemuIsWLXJNV6+44go3zj59r0bJatSq5vb58+c/7jU0/sOHD7fzzz/frr766oD/Avg2b95sWbJksQsuuMCGDh1q7du3T7KJffPmza1AgQL28ccfu8bIauY6ffr0UJN6xA815X3wwQftxx9/dJ8NNbdX806aeEYXfx/qf008mYSa1C9evNiNmxpqX3755dauXTu3LmsbrQauiLyff/7Zevbs6RojDxgwwC666KJILxJOoxl2xYoV3TGuJgLRBCBJNcPWRCD58uVzj4c3w1bjezXDvuGGGyLwVyCp9VHb1WeffdZNTHDVVVfZG2+8Ydddd13oeTpvmTVrll1//fXsH+PYX3/9ZS+88II779HkFF9++aU7V01q4iZEFkEpHEczVGjDrJPcr7/+2kaPHm1NmzZ1szZ17do1FHT67bff3AZfO2et5Ho+op/Ga+DAgVauXDk3Y5c22No59+vXzzp16uRmi3nyySfdrGuzZ892P/uzQPkS/4zI0EGwZgTSrIeacWvChAkuKBV+kuu7/fbb3QH4ihUr3I7YH8OknovY9+2337rZo7Td1vhywB2dNFPt2LFjrVatWm7G08Refvlly5QpkzsZ1leNYYcOHaxw4cJuO611mG1xdJwI33vvvW5/OnLkSDe7KaKb9pcPPfSQFStWzH799Ve3TvXt29d27txp999/v02aNMmtk/4+UrNg6hhJgWEdC4dTMOu8886L2N+C49dHzVCqC3IrV650x7M6NlIgQmOZeJvJ/jF+/fTTT2691vr5xBNPEICMZpFO1UJ01mSrLt6ftWvTpk3eI4884mXJksX1uFAzSDVevf/++12/oWXLlkV6kXGK6DsUX1RuoHICUZmlauVVdhueuuynKWtWTDXmDUfj3ejnj9+ZpJtrnBnr6KM+USqFV58a9TVRY2yVxfsTTSTVZ0qluGpq7s8MhuihMdE4quk5ohvNsM+OUr5GjRq58vXwmWfZF8aP/1r//LEOnzGeEs3oxeVxHEdX1lWSN2rUKDt48KAVKVLElYGozKtChQquFESlIboK/8UXX7gMDUQ3ZcXs3bvXXXV/5JFHrHXr1q6sR1R+N3jwYHclQeV4M2bMsNKlS9t9993nruCvX78+0ouPE/jzzz9D37dq1cqV+qikR+nqoquByopSWa7KMbX+hiPDIrqpdFblQCqZDk8z/68EZ13Z9+lKMdk00Sljxox2ySWXuPVT2+Y2bdrY22+/7crjn3nmGbfO+ubMmePK6FV6+/nnnx+3LiPyNCavv/66lSxZMtKLgpOYO3euO8ZVdrjWucyZM7vjXpXFKmMqd+7cbrv78MMPW5cuXey1115z694vv/xin3zyidsWK+NGyDKOXqoGGDdunBUvXtwd96ryQ9gXxm7Gk8ot+/Tp48rxfvjhh/9c/zTWWldz5MgROnYiQyp6MTJIUp06dWzEiBHuoPm2225zO3EdFFeqVMkFqHRQrJ14wYIFI72oOAVbtmxxQSilMd98883uPn/DrI22vr/77rvdBl8be/UyKV++vJUpU8YFIxE9/v77b9fTQvbv3x8aRwUR1SdMpSMKSvXo0cOdJG3atMkdfKusZNCgQRFeepwqBZO0TmbPnt2dFKmMRH2EFHz0D6qT6omggy7/QE1lneqj8PTTT1vevHkj8ncgaX757J133mmfffaZ6++mk2Bd7Jk/f75dc801rtxAZWAPPPCAnXPOOe65lStXtrJly0Z68XECOmZCdFO5nvplKuirdU2BYZ8CVNquqlRW653W0VtvvdWtcyq1VS8aSn9ih3rjqgVJ7969Q73CqlSpEunFQjKpB6ou1Gj/uHv3bneRXb0z1b7ipptuOuF2V/tZ/xhJ67ouuKslCaITIX4kSY3/tPPVTY2RdXVIASlRM0id8Po/I/r7DrVt29ad5CqgkVQ2hRQqVMid9CqgoYMy9U147733Qo14EXnq3aZ1UwFi0djoANunIIR6Yahxq4LGOiBT/xk/U0oH0v4VXkS3rFmzupMlBRTfeecdN4bqY6KeJq+++qp7TuKAlNZTP2Clz4KavSq4QUAq+oRfrVfwWNtp0RVdXRwoWrSoOyletmyZm4hC32tCCQJSwJln0Cg4oZNa9ZhR/yFdaFV2lLLFdSwk2bJlc8EMNcjWxVgCUrE73uqVq/0pvW9jj45llNnYuXNnl0msc5QPPvjAZTnq/vBJB8KF977VxXYdE2/fvj0ifwNOUaTrBxF9/BrcDz/80DvvvPO86dOnJ7gfsYW+Q/Hjp59+8i699FKvWbNm3sKFC71bbrnFGzx48HHPW79+vbdy5UrXn2b16tWhuntq6WOLtr158uQJ9RjatWuX16lTJy9Dhgxe9erVvcmTJ7vPROLeCmPHjnV9Ad95552ILTv+mz9mmqa8WLFirtffbbfd5hUpUiRBr0b1tVGfPwAp23NI+1JtS7VN1fZUdDyU1HEP+8/4QB+w2KEexpkzZ/beffdd93P4erlt2zavW7duXrp06bwFCxYk+L3w5+l4SMdR06ZNC3DJcTrIlMJx/MhyjRo13JX3JUuWJLgfsYW+Q/FDJZXjx493V4CGDh3qyn6UNXPZZZe5q0D6qmnjVeqlUh/NkKnMRj/bjSu8sUNjrDLaFi1auNIuyZUrl1t/dX/16tXdeqxyLl099Ev21AdOWTXqURQ+/TUiz7+S63/1x0yZGSqT15VgZUO+//77rlejn9Wo8iGVHQBI2QwalQSph5T2rcoslhNNE8/+Mz7QByw2qB1F9+7d3fGszl38THB//1mgQAFXkqk2I8qESipDSj3F1INKx82qMkB0Y83ECelAeeDAga5HjcqBEDvCy/QS9x1SOZfGVGVeqrHetm2bLV++3E05Tt+h6KcDZ38SAt00tk2aNHHltDrI1smsesJVq1bNjbePA7HYozFTuZYml1DQWBcK8uTJ49LVdZClAzEFprTuigKUOgDT45rMANHDP1DWNvexxx5z5SRqYO9TQPnAgQOur1StWrUS9MIAkDpohg1EJ/V+0jqp45qJEye646HwgJPooquOizRBgR+sCi/Ze+ihh9wFOo6HYkMapUtFeiEQ3Vk2aoytRrvaaSP66Uq7P3OMsmZ0lV0zKD755JOh5yiT4q233rLff//dNVJWE93ChQvbhx9+6PomJNVAGdFFMwGp38Xhw4ddHwxlzCSFHhjRT83IdVVw0aJFbmIB9RBSfzefvlcWo5rzaka+/PnzH/cauoqoz4Fm01TvIUSfjz76yGW5aXY9TR5Su3Zt18xeB8w64FamlPa56i+l7A0AwVBfKe1P1XuTZthA5Hz11VcuEUL7RAWd1q5dG2pS37Fjx+Oer4tymvwnvLfU999/7y7Mal96ww03ROCvwOkgKIX/pGwMzUiC2KCT29tvv93NtqfglGan0Ia9b9++CZ6n0i7NYLFq1Sq78MILXfq6dgIEMWKHdtZqZq0rQ2qIraCFL/EVJUQnHUgpI1VX7JW1qGzFXbt2ufFUU3NdLVRAWVcKZ8+e7X5OPLaMdfTyx0Zjq4sB9evXd6V6O3bscJNJKDvqjjvucN/rooDGXOWY4TOCAUh9amY+YcIEl8VIZjEQPK1/ym7SBD7KftLFcp277Ny501V3TJo0yZXz6SKc1lFdWNc+U/tPTQST+PhYM9gidhCUAuI0i0ZX4BVMVPaFrrpr4+6fIGljrgwbfX/VVVfZgw8+6H7P39AjdnCFN3apLE9X/pSefuWVV7qZ13744Qd34PX000+7gzD1Dlu/fr0bVwWnNPMpYotKggYPHmx79uxxPWzUD0wUqFI5tS4OqOyyWbNmrg/YiBEjXJASQGRwLAQEH5DS8Y0qczRrsPpn6oKd1kVdlNNtyJAh7qsqQHS/Mo/VokT9Vf3qDtbd2EU6BBDHfYeU8hred0jNzdWbRie/Ckjpe/oOxcd0x9qhM91xbFBweN++fa7XgXomqHxLGYqi8jsFMDJmzOgOwJRZowMvradqYq4gMk2vY4suCKxbt85duV25cmUoKFWwYEGbPHmyC0zqwoBKp9977z1Kp4EI41gICI7K2bt16+aOh9q0aeOOkTR5T/Pmzd25jC6sq/JD+8YuXbq49XPGjBnuArz2qbrfbzvCuhu7CEoBcUrleGqC7Pcd0sadvkPxSeWZyqwRrhJFvy1btrjyWh1MqWef+OufgsX6XpmOs2bNcs06FZTS+qxZZtRzCrFFzeo//vhjN4PQK6+84sZQB9yi/mAKTmq2TK3HBKQAAGcTleup/YR6Z2oykPDydVV8KOCUKVMmVwKvYyRlSmm/unr1ancxh3OY+ED5HhDn6DsERA813lSftxdffNHNlKgMt/bt2ycZTFRvODX9XLFihQtW+Osrgcfo5Y+RevspM9UvndZEIdoWa1pqTTyhPhl+YEoYUwDA2dyKQucq2hc+++yzbv+pzPA33njDlbX71HNTF+y0L1UgioBU/OAICIhzavSnjCmd1CprSrNS+AhIAcFSsKJo0aIu80lTGSs4pWadfkBCQQ1dFZRs2bK59dfPntH6qscJXkR3QOqdd95xM5+q8aoOnDXbnq7+aizVxHzz5s2u5PbTTz8N/S5jCgA4m1tRjB492h3vtG3b1po2ber6pCogpWMiP4dGF3r0OAGp+MNREHAW9R1SSix9h4DI+fPPP0Pfq5xLzTwVNNZVQVFQQwdl6vemVPYKFSok+H0CydFDV3R9OjjW2Ggqa80G1L9/f5flpqb1tWrVcj39vvzySxeYevfdd13p5rhx41yTVgAAznY6V9FkIAo86cKd+uPKicraCUjFF8r3gLMQpSJAcP7++2/Lly+f+17TGYtmmBE199TVQGXUaOYZBaE2bdrkSm03bNhgy5Yt48AriinLrWTJki4gpau56hn1+uuv2+zZs0PbWPUQU6N6TTn/0UcfuXK+3377zW2H1ScMAAAknEFcHn74YTfhC+IfZ6XAWYiAFBAMZcco4DRnzpzQuqemnj6V791///0uw0Y9hnRlsEOHDqFMKQWk/HI+RJdDhw65MgIFlnR9T1dz9+zZY8uXL3dfRfcrCHXTTTfZX3/9ZTt37nT3n3POOQSkAABIRMdBfimfZhEPbzuC+MWZKQAAqaRgwYLuq2ZHXLRokQtS5MqVK8Fzhg4dal988YU78FKQSs3Q1cjTn1WGGdmiU8aMGV1ZdPbs2a169epubFu0aOEamU+cONE1ZPXLLVWWoPH8559/Ir3YAABENdqOnH0o3wMAIIBUdE1trMCUPyOb3xhb2VOHDx9232u2mQcffND9HmW20SWp8dB9ynLr2LGj5cyZ032vcoMZM2a4Uk1lvalh/eOPP+4aoH/99dehQCUAAPhvHA/FP4JSAAAEMOue0tAVlCpevLi1b9/eNTdXmV6OHDlcQErfDx8+3GXUIDoPiNUfSv2g6tatG3pM46beXyrlK1GihM2bN88GDBhg06dPdwHJqlWr2q+//mqffPKJVatWLaJ/BwAAQLQhKAUAQAAUoOjdu7fLilLwqXLlykk+j2mOo5OCiAoq7dixwxo2bGj16tWzxo0bW82aNV2W1LfffmtdunRx32vmPQWw1Ng8T548rryvVKlSkf4TAAAAog5BKQAAArJ27Vrr2bOny4zSDHsNGjQIPeaX8yF6Z9pr2bKlHThwwGW3VapUyfX/0oyJCjBeffXVbvz69u3rmpgrM4rxBAAAODmCUgAABOjnn392GVNbt261l156yapUqRLpRUIyst369OnjyvkUfFJT8wULFtizzz7ryvhWrVplZcuWdV/V9FwlfAQbAQAAToygFAAAAfvxxx9twoQJbnYZmnfGXn+we+65xwWmnnjiCatVq5a7X7PtzZw503766Sf7+OOPXcCRHlIAAAAnR1AKAIAIYlaZ2Mx204yKoowp9ZgKR18wAACAU8NRMAAAEURAKvaUK1fOxowZ48ryhgwZ4kr4whGQAgAAODUcCQMAAJxGYGr06NGWIUMGu++++2zRokWRXiQAAICYQ1AKAADgNANT6gtWvHhxK1q0aKQXBwAAIObQUwoAAOAMHD582DJmzBjpxQAAAIg5BKUAAAAAAAAQOMr3AAAAAAAAEDiCUgAAAAAAAAgcQSkAAAAAAAAEjqAUAAAAAAAAAkdQCgAAAAAAAIEjKAUAAAAAAIDAEZQCAAAAAABA4AhKAQAAAAAAIHAEpQAAAAAAABA4glIAAAAAAACwoP0/dd5lKxP4eLoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Compute predictions ---\n",
    "teacher_preds = teacher.predict(X_test)\n",
    "teacher_labels = np.argmax(teacher_preds, axis=1)\n",
    "\n",
    "student_preds = student.predict(X_test)\n",
    "student_labels = np.argmax(student_preds, axis=1)\n",
    "\n",
    "# --- Class names ---\n",
    "class_names = ['Assistive', 'KOA_Early', 'KOA_Mild', 'KOA_Severe', \n",
    "               'NonAssistive', 'Normal', 'PD_Early', 'PD_Mild', 'PD_Severe']\n",
    "\n",
    "# --- Compute per-class accuracy ---\n",
    "def per_class_accuracy(y_true, y_pred, classes):\n",
    "    accs = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        idx = np.where(y_true == i)[0]\n",
    "        if len(idx) > 0:\n",
    "            acc = np.mean(y_pred[idx] == y_true[idx])\n",
    "            accs.append(acc)\n",
    "        else:\n",
    "            accs.append(np.nan)  # no samples for this class\n",
    "    return np.array(accs)\n",
    "\n",
    "teacher_accs = per_class_accuracy(y_test, teacher_labels, class_names)\n",
    "student_accs = per_class_accuracy(y_test, student_labels, class_names)\n",
    "\n",
    "# --- Plot comparison ---\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x - width/2, teacher_accs*100, width, label='Teacher', alpha=0.8)\n",
    "plt.bar(x + width/2, student_accs*100, width, label='Student', alpha=0.8)\n",
    "plt.xticks(x, class_names, rotation=45)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Per-Class Accuracy: Teacher vs Student')\n",
    "plt.ylim(0, 105)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b745cad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\GaitLab\\GaitEnv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:405: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     loss=lambda y_true, y_pred: distillation_loss(y_true, y_pred, teacher_probs=teacher_preds_soft, \n",
      "                                                 temperature=temperature, alpha=alpha),\n",
      "\n",
      "  return {key: serialize_keras_object(value) for key, value in obj.items()}\n"
     ]
    }
   ],
   "source": [
    "student.save(\"student_model.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GaitEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
