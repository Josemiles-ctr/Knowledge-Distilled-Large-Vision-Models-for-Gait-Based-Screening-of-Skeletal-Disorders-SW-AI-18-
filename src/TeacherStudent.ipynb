{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39774d04",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\user\\\\Desktop\\\\GaitLab\\\\GaitLab\\\\src\\\\keypoints_csv\\\\ts_data\\\\X_seq_len64_stride32.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m y_PATH = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mGaitLab\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mGaitLab\u001b[39m\u001b[33m\\\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mkeypoints_csv\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mts_data\u001b[39m\u001b[33m\\\u001b[39m\u001b[33my_seq_len64_stride32.npy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load sequences and labels\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m y = np.load(y_PATH, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Basic checks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\OneDrive\\Desktop\\Gaitlab\\GaitLab\\venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    425\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    428\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\user\\\\Desktop\\\\GaitLab\\\\GaitLab\\\\src\\\\keypoints_csv\\\\ts_data\\\\X_seq_len64_stride32.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "X_PATH = r\"C:\\Users\\user\\Desktop\\GaitLab\\GaitLab\\src\\keypoints_csv\\ts_data\\X_seq_len64_stride32.npy\"\n",
    "y_PATH = r\"C:\\Users\\user\\Desktop\\GaitLab\\GaitLab\\src\\keypoints_csv\\ts_data\\y_seq_len64_stride32.npy\"\n",
    "\n",
    "# Load sequences and labels\n",
    "X = np.load(X_PATH, allow_pickle=True)\n",
    "y = np.load(y_PATH, allow_pickle=True)\n",
    "\n",
    "# Basic checks\n",
    "print(\"Loaded X shape:\", X.shape)\n",
    "print(\"Loaded y shape:\", y.shape)\n",
    "print(\"NaNs in X:\", np.isnan(X).sum())\n",
    "print(\"Infs in X:\", np.isinf(X).sum())\n",
    "\n",
    "# Label distribution\n",
    "print(\"\\nLabel distribution (counts):\")\n",
    "print(Counter(y))\n",
    "\n",
    "# Unique classes\n",
    "class_names = np.unique(y)\n",
    "print(\"\\nUnique labels (classes):\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45547d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# --- Handle NaNs ---\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Impute NaNs with median per feature across all sequences\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m num_sequences, seq_len, num_features = \u001b[43mX\u001b[49m.shape\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feature_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features):\n\u001b[32m      8\u001b[39m     feature_values = X[:, :, feature_idx]\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de82c37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# --- Build & compile ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m input_shape = (\u001b[43mX_train\u001b[49m.shape[\u001b[32m1\u001b[39m], X_train.shape[\u001b[32m2\u001b[39m])\n\u001b[32m     36\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(np.unique(y_train))\n\u001b[32m     38\u001b[39m teacher = build_teacher_model(input_shape, num_classes)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_teacher_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    High-capacity TCN teacher model.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "    x = inputs\n",
    "    \n",
    "    # --- TCN Blocks (6 blocks, wider filters) ---\n",
    "    for i in range(6):\n",
    "        x_prev = x\n",
    "        x = layers.Conv1D(filters=128, kernel_size=3, padding='causal', activation=None, name=f'conv1d_teacher_{i}')(x)\n",
    "        x = layers.BatchNormalization(name=f'bn_teacher_{i}')(x)\n",
    "        x = layers.Activation('relu', name=f'act_teacher_{i}')(x)\n",
    "        x = layers.Dropout(0.2, name=f'drop_teacher_{i}')(x)\n",
    "        # Residual connection\n",
    "        if x_prev.shape[-1] == x.shape[-1]:\n",
    "            x = layers.Add()([x_prev, x])\n",
    "    \n",
    "    # Global pooling\n",
    "    x = layers.GlobalAveragePooling1D(name=\"gap_teacher\")(x)\n",
    "    \n",
    "    # Feed-forward for extra capacity\n",
    "    x = layers.Dense(256, activation='relu', name=\"ff_teacher\")(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', name=\"output_teacher\")(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=\"teacher_model\")\n",
    "    return model\n",
    "\n",
    "# --- Build & compile ---\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "teacher = build_teacher_model(input_shape, num_classes)\n",
    "teacher.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "teacher.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# --- Encode class labels to integers ---\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Optional: save class names\n",
    "class_names = le.classes_\n",
    "print(\"Class names:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a41639f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'teacher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m checkpoint = ModelCheckpoint(\u001b[33m'\u001b[39m\u001b[33mbest_teacher_model.keras\u001b[39m\u001b[33m'\u001b[39m, monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- Train teacher model ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m history_teacher = \u001b[43mteacher\u001b[49m.fit(\n\u001b[32m     11\u001b[39m     X_train, y_train_enc,\n\u001b[32m     12\u001b[39m     validation_data=(X_val, y_val_enc),\n\u001b[32m     13\u001b[39m     epochs=\u001b[32m50\u001b[39m,           \u001b[38;5;66;03m# increase later if needed\u001b[39;00m\n\u001b[32m     14\u001b[39m     batch_size=\u001b[32m16\u001b[39m,       \u001b[38;5;66;03m# CPU-friendly\u001b[39;00m\n\u001b[32m     15\u001b[39m     callbacks=[early_stop, checkpoint],\n\u001b[32m     16\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# --- Evaluate on test set ---\u001b[39;00m\n\u001b[32m     20\u001b[39m test_loss, test_acc = teacher.evaluate(X_test, y_test_enc, verbose=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'teacher' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# --- Callbacks ---\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_teacher_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# --- Train teacher model ---\n",
    "history_teacher = teacher.fit(\n",
    "    X_train, y_train_enc,\n",
    "    validation_data=(X_val, y_val_enc),\n",
    "    epochs=50,           # increase later if needed\n",
    "    batch_size=16,       # CPU-friendly\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- Evaluate on test set ---\n",
    "test_loss, test_acc = teacher.evaluate(X_test, y_test_enc, verbose=0)\n",
    "print(\"Teacher Test Accuracy: {:.2f}%\".format(test_acc * 100))\n",
    "\n",
    "# --- Predictions & classification report ---\n",
    "y_pred = np.argmax(teacher.predict(X_test), axis=1)\n",
    "print(classification_report(y_test_enc, y_pred, target_names=class_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
